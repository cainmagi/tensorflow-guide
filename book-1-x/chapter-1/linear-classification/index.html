



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="本节介绍如何使用顺序模型(sequential model)来编写一个线性分类器，使用sigmoid函数激活，并验证其效果。">
      
      
        <link rel="canonical" href="https://cainmagi.github.io/tensorflow-guide/book-1-x/chapter-1/linear-classification/">
      
      
        <meta name="author" content="Yuchen Jin (cainmagi)">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../../assets/images/icons/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>线性分类 - Tensorflow手札</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.982221ab.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#ff7043">
      
    
    
      <script src="../../../assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,400,400i,600,700,900|Roboto+Mono">
        <style>body,input{font-family:"Noto Serif SC","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../../stylesheets/main.css">
    
      <link rel="stylesheet" href="../../../stylesheets/extensions.css">
    
      <link rel="stylesheet" href="../../../stylesheets/simpleLightbox.min.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-119875813-2", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="deep-orange" data-md-color-accent="orange">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://cainmagi.github.io/tensorflow-guide/" title="Tensorflow手札" class="md-header-nav__button md-logo">
          
            <img src="../../../assets/images/icons/Tensorflow.svg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Tensorflow手札
            </span>
            <span class="md-header-nav__topic">
              线性分类
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/cainmagi/tensorflow-guide" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    cainmagi/tensorflow-guide
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../.." title="TF 1.x" class="md-tabs__link md-tabs__link--active">
          TF 1.x
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://cainmagi.github.io/tensorflow-guide/" title="Tensorflow手札" class="md-nav__button md-logo">
      
        <img src="../../../assets/images/icons/Tensorflow.svg" width="48" height="48">
      
    </a>
    Tensorflow手札
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/cainmagi/tensorflow-guide" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    cainmagi/tensorflow-guide
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1" checked>
    
    <label class="md-nav__link" for="nav-1">
      TF 1.x
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        TF 1.x
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../.." title="扉页" class="md-nav__link">
      扉页
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-2" type="checkbox" id="nav-1-2" checked>
    
    <label class="md-nav__link" for="nav-1-2">
      从线性问题入门
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-2">
        从线性问题入门
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="本章总说" class="md-nav__link">
      本章总说
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../hello-world/" title="Hello world!" class="md-nav__link">
      Hello world!
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        线性分类
      </label>
    
    <a href="./" title="线性分类" class="md-nav__link md-nav__link--active">
      线性分类
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="理论" class="md-nav__link">
    理论
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="感知机" class="md-nav__link">
    感知机
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" title="Sigmoid函数" class="md-nav__link">
    Sigmoid函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="求解问题" class="md-nav__link">
    求解问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" title="交叉熵" class="md-nav__link">
    交叉熵
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="解线性多分类问题" class="md-nav__link">
    解线性多分类问题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="代码规范" class="md-nav__link">
    代码规范
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="数据生成" class="md-nav__link">
    数据生成
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="定义线性顺序模型" class="md-nav__link">
    定义线性顺序模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="初始化方法" class="md-nav__link">
    初始化方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="构造方法" class="md-nav__link">
    构造方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="训练和测试方法" class="md-nav__link">
    训练和测试方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" title="调试" class="md-nav__link">
    调试
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
        <li class="md-nav__item">
          <a href="#__source" title="来源" class="md-nav__link md-nav__link--active">
            来源
          </a>
        </li>
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../release-notes/" title="更新记录" class="md-nav__link">
      更新记录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../licenses/" title="协议" class="md-nav__link">
      协议
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="理论" class="md-nav__link">
    理论
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="感知机" class="md-nav__link">
    感知机
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" title="Sigmoid函数" class="md-nav__link">
    Sigmoid函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="求解问题" class="md-nav__link">
    求解问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" title="交叉熵" class="md-nav__link">
    交叉熵
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="解线性多分类问题" class="md-nav__link">
    解线性多分类问题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="代码规范" class="md-nav__link">
    代码规范
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="数据生成" class="md-nav__link">
    数据生成
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="定义线性顺序模型" class="md-nav__link">
    定义线性顺序模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="初始化方法" class="md-nav__link">
    初始化方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="构造方法" class="md-nav__link">
    构造方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="训练和测试方法" class="md-nav__link">
    训练和测试方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" title="调试" class="md-nav__link">
    调试
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
        <li class="md-nav__item">
          <a href="#__source" title="来源" class="md-nav__link md-nav__link--active">
            来源
          </a>
        </li>
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="_1">线性分类<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">摘要</p>
<p>本节介绍如何使用顺序模型(sequential model)来编写一个线性分类器，使用sigmoid函数激活，并验证其效果。</p>
</div>
<h2 id="_2">理论<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="_3">问题描述<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>考虑我们有如下的二分类数据集<span><span class="MathJax_Preview">(\mathbf{x},~y_i) \in \mathbb{D}_i</span><script type="math/tex">(\mathbf{x},~y_i) \in \mathbb{D}_i</script></span>，并且有一个未知的常数向量<span><span class="MathJax_Preview">\mathbf{a}_i</span><script type="math/tex">\mathbf{a}_i</script></span>和未知的常数标量<span><span class="MathJax_Preview">c_i</span><script type="math/tex">c_i</script></span>，使得：</p>
<div class="overflow">\begin{equation}
    y_i = \left\{
    \begin{aligned}
        0, &amp;&amp; \mathbf{a}_i^T \mathbf{x} + c_i \leqslant 0, \\
        1, &amp;&amp; \mathbf{a}_i^T \mathbf{x} + c_i &gt; 0.
    \end{aligned}
    \right.
\end{equation}</div>

<p>其中，<span><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>可以看成是某超平面的（未标准化的）法向量，那么<span><span class="MathJax_Preview">\mathbf{a}^T \mathbf{x} + c = 0</span><script type="math/tex">\mathbf{a}^T \mathbf{x} + c = 0</script></span>是该超平面的截距式定义，亦即该平面与<span><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span>轴的交点可以显式表述为<span><span class="MathJax_Preview">x_i^{(0)} = - \frac{c}{a_i}</span><script type="math/tex">x_i^{(0)} = - \frac{c}{a_i}</script></span>。由此可知，式<a href="#mjx-eqn-1"><span><span class="MathJax_Preview">(1)</span><script type="math/tex">(1)</script></span></a>显式定义了一个点在超平面的哪一侧。特别地，若<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>是一个二维向量，则该超平面退化为一维平面；若<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>是一个标量，则该超平面退化为一条直线。</p>
<p>若我们定义<span><span class="MathJax_Preview">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</script></span>，有</p>
<div class="overflow">\begin{equation}
    \mathbf{y} =
    \begin{bmatrix}
      y_1 \\
      y_2 \\
      \vdots \\
      y_n
    \end{bmatrix}, ~~
    \mathbf{A} = 
    \begin{bmatrix}
      \mathbf{a}^T_1 \\
      \mathbf{a}^T_2 \\
      \vdots \\
      \mathbf{a}^T_n
    \end{bmatrix}, ~~
    \mathbf{c} = 
    \begin{bmatrix}
      c_1 \\
      c_2 \\
      \vdots \\
      c_n
    \end{bmatrix}.
\end{equation}</div>

<p>则我们可以认为</p>
<div class="overflow">\begin{align}
   \mathbf{y} = \left\{ \begin{bmatrix}\hat{y}_1 &gt; 0 &amp; \hat{y}_2 &gt; 0 &amp; \cdots &amp; \hat{y}_n &gt; 0\end{bmatrix}^T, ~ \left| ~ \hat{\mathbf{y}} = \mathbf{A} \mathbf{x} + \mathbf{c} + \boldsymbol{\varepsilon} \right. \right\},
\end{align}</div>

<p>其中<span><span class="MathJax_Preview">\boldsymbol{\varepsilon}</span><script type="math/tex">\boldsymbol{\varepsilon}</script></span>是一个定义噪声的向量。</p>
<p>我们可以把向量<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>的元素看成是互不相关的多个超平面对向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>各自独立的分类结果。即<span><span class="MathJax_Preview">y_i = \{ \hat{y}_i&gt;0 ~ | ~ \hat{y}_i = \mathbf{a}_i^T \mathbf{x} + c_i + \varepsilon_i \}</span><script type="math/tex">y_i = \{ \hat{y}_i>0 ~ | ~ \hat{y}_i = \mathbf{a}_i^T \mathbf{x} + c_i + \varepsilon_i \}</script></span>。由于每个超平面构成一个二分类，如果把每个二分类看作是向量是否属于这个类的测度，那么<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>可以被看作是一个多分类的结果，尽管向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>可能被同时分入多个类中。</p>
<p>假设我们的数据集<span><span class="MathJax_Preview">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</script></span>符合<a href="#mjx-eqn-3"><span><span class="MathJax_Preview">(3)</span><script type="math/tex">(3)</script></span></a>定义的数据分布特征。我们的基本要求是，在我们不知道<span><span class="MathJax_Preview">\mathbf{A},~\mathbf{c}</span><script type="math/tex">\mathbf{A},~\mathbf{c}</script></span>的情况下，使用大量<span><span class="MathJax_Preview">(\mathbf{x}^{(k)},~\mathbf{y}^{(k)}) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x}^{(k)},~\mathbf{y}^{(k)}) \in \mathbb{D}</script></span>样本训练一个线性分类器，使得当我们给定任意一个新样本<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>的时候，分类器能推断出其对应的<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>来（亦即是否属于该分类）。</p>
<p>在这个问题里，我们虽然不知道<span><span class="MathJax_Preview">\mathbf{A},~\mathbf{c}</span><script type="math/tex">\mathbf{A},~\mathbf{c}</script></span>，但我们知道由<a href="#mjx-eqn-3"><span><span class="MathJax_Preview">(3)</span><script type="math/tex">(3)</script></span></a>确定的线性关系，因此，我们可以随机生成一组<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b}</span><script type="math/tex">\mathbf{W},~\mathbf{b}</script></span>，构建线性模型：</p>
<div class="overflow">\begin{align}
   \tilde{\mathbf{y}} = \sigma ( \mathbf{W} \mathbf{x} + \mathbf{b} ).
\end{align}</div>

<p>其中，可微函数<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>是一个将实数空间<span><span class="MathJax_Preview">\mathbb{R}^n</span><script type="math/tex">\mathbb{R}^n</script></span>映射到有限范围的实数空间<span><span class="MathJax_Preview">[0,~1]^n</span><script type="math/tex">[0,~1]^n</script></span>内的函数。特别地，<span><span class="MathJax_Preview">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</span><script type="math/tex">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</script></span>。因此，可以将<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>看作是二分类布尔函数的插值函数。理论上，只要我们找到<span><span class="MathJax_Preview">\mathbf{W}=\mathbf{A}</span><script type="math/tex">\mathbf{W}=\mathbf{A}</script></span>，<span><span class="MathJax_Preview">\mathbf{b}=\mathbf{c}</span><script type="math/tex">\mathbf{b}=\mathbf{c}</script></span>，则该线性分类器可以直接拟合出原分布来。</p>
<h3 id="_4">感知机<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>我们将<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>定义的线性模型称为<span></span><strong>单层感知机 (Single-layer perceptron)</strong><span></span>模型。它包含一个权重矩阵<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>和一个偏置矩阵<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>。事实上，可以将<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>改写成如下形式</p>
<div class="overflow">\begin{align}
   \tilde{\mathbf{y}} = \sigma \left( \begin{bmatrix} \mathbf{W} &amp; \mathbf{b} \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ 1 \end{bmatrix} \right).
\end{align}</div>

<p>可见偏置本身可以看成是输入向量多了一个常数元素的等价模型。</p>
<p>感知机是最早的神经网络形式，它非常孱弱，只能解线性问题，但却为神经网络后来的发展开了先河。在单层感知机里，我们视输入向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>的每个元素为一个“神经元”，矩阵<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>和偏置<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>将我们的输入映射到输出层<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>，输出层的每个元素也视为一个神经元。在这个过程中，<span><span class="MathJax_Preview">W_{ij}</span><script type="math/tex">W_{ij}</script></span>作为<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>行<span><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>列的元素，代表了连接两个神经元的权重。我们用红线代表正值，蓝线代表负值，感知机可以被图示为</p>
<p><img alt="感知机模型" class="img-fluid" src="../../../assets/images/book-1-x/lincls-lp.svg" tag="5" title="感知机模型" /></p>
<p>线性感知机的输出也是输入的线性组合，但我们可以添加激活函数，即<span><span class="MathJax_Preview">\sigma(\cdot)</span><script type="math/tex">\sigma(\cdot)</script></span>将其映射到非线性空间。这要求我们添加的激活函数是一个非线性函数。</p>
<p>事实上，将单层感知机层叠，前一层的输出作为后一层的输入，就构建出早期的神经网络。这种网络每一层都是全连接的（两个神经元之间总是有权重，尽管值可能为0），每一层都有激活函数。理论上，任意一个两层堆叠的感知机，只要神经元数目足够多，就可以拟合出任意一个非线性函数。然而，实际测试中，这一理论的效果并不尽如人意，因此又有陆续地改进，才有了后来的深度学习。饮水思源，鉴往知来，我们也将从这个简简单单的单层模型开始，走上学习“深度学习”之旅。</p>
<h3 id="sigmoid">Sigmoid函数<a class="headerlink" href="#sigmoid" title="Permanent link">&para;</a></h3>
<p>在上述介绍中，我们没有解决的两个问题是，</p>
<ul>
<li>如何定义插值函数<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>？</li>
<li>如何找到合适的<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b}</span><script type="math/tex">\mathbf{W},~\mathbf{b}</script></span>？</li>
</ul>
<p>我们首先讨论第一个问题。一般地，多分类问题中，如果各个分类彼此并非相斥，且不一定要将结果分入任一类的话，我们可以用<span></span><strong>Sigmoid</strong><span></span>函数来定义<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>，亦即</p>
<div class="overflow">\begin{align}
   \sigma(\mathbf{x}) = \frac{1}{ 1 + e^{-\mathbf{x}}}.
\end{align}</div>

<p>它同时满足<span><span class="MathJax_Preview">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</span><script type="math/tex">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</script></span>，且是一个单调函数。以下代码向我们展示了这种函数的特性：</p>
<div class="superfences-tabs">
<input name="__tabs_1" type="radio" id="__tab_1_0" checked="checked" />
<label for="__tab_1_0">Python</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">test_sigmoid</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">test_sigmoid</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_1" />
<label for="__tab_1_1">Output</label>
<div class="superfences-content"><div class="overflow"><img alt="Sigmoid函数" class="img-fluid" src="../../../assets/images/book-1-x/lincls-sigmoid.svg" tag="1" title="Sigmoid函数"></div></div>
</div>
<p>使用sigmoid函数的一大好处是，它的导数求解非常简单，很适合用来做神经网络这样一个复杂模型的激活函数。注意虽然<span><span class="MathJax_Preview">\sigma(\mathbf{x})</span><script type="math/tex">\sigma(\mathbf{x})</script></span>和<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>都是向量，这意味着导数是Jacobian矩阵，但由于<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>是一个对<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>各元素独立的解析函数，这个Jacobian矩阵实际上是一个对角矩阵，对角线上第j个元素的值为</p>
<div class="overflow">\begin{align}
   \left. \frac{ \partial \sigma(x) }{ \partial x } \right|_{x=x_j} = \left. - e^{-x} \left( - \frac{1}{\left( 1+e^{-x} \right)^2} \right) \right|_{x=x_j} = - \sigma(x_j) \sigma(1 - x_j).
\end{align}</div>

<p>可见，该函数的导数和计算函数本身的复杂度相若，可以做到快速求导。</p>
<h3 id="_5">求解问题<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>接下来，我们需要解决第二个问题，亦即找到<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b}</span><script type="math/tex">\mathbf{W},~\mathbf{b}</script></span>。这一问题通常可以写成反问题的形式：</p>
<div class="overflow">\begin{align}
   \arg \min_\limits{\mathbf{W},~\mathbf{b}} \sum_{k=1}^N \mathcal{L} \left( \mathbf{y}^{(k)},~ \sigma ( \mathbf{W} \mathbf{x}^{(k)} + \mathbf{b} ) \right).
\end{align}</div>

<p>最简单的情况下，我们可以把<span></span><strong>损失函数(loss function)</strong><span></span>定义为</p>
<div class="overflow">\begin{align}
   \mathcal{L} \left( \mathbf{y},~ \tilde{\mathbf{y}} \right) = \lVert \mathbf{y} - \tilde{\mathbf{y}} \rVert_2^2.
\end{align}</div>

<p>我们称<a href="#mjx-eqn-7"><span><span class="MathJax_Preview">(7)</span><script type="math/tex">(7)</script></span></a>为<span></span><strong>逻辑斯蒂回归(logistic regression)</strong><span></span>。有趣的是，虽然这个术语叫“回归”，但它解的其实是个分类问题。但是，既然这是一个分类问题，我们可以不使用这个损失函数，而是从概率论的角度看待这个问题。由此，我们引出一个新的损失函数：“交叉熵”。</p>
<h3 id="_6">交叉熵<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>我们视sigmoid函数输出的值为一个概率，表示分类器对预测结果的确信程度，记<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b} \in \boldsymbol{\Theta}</span><script type="math/tex">\mathbf{W},~\mathbf{b} \in \boldsymbol{\Theta}</script></span>，则</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \mathbf{p}(y_i=1|\mathbf{x};~\boldsymbol{\Theta}) &amp;= \sigma(\mathbf{x};~\boldsymbol{\Theta}), \\
        \mathbf{p}(y_i=0|\mathbf{x};~\boldsymbol{\Theta}) &amp;= 1 - \sigma(\mathbf{x};~\boldsymbol{\Theta}).
    \end{aligned}
\end{equation}</div>

<p>注意这里的概率向量的含义是，其中第i个元素表明第i个超平面分类结果的确信程度。</p>
<p>然而，这个概率只是分类器对分类结果的确信程度，却并非是分类准确度的概率，实际上，分类准确度的概率，应当表述为</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \mathbf{p}(\mathbf{y}|\mathbf{x};~\boldsymbol{\Theta}) &amp;= \mathbf{p}(y_i=1|\mathbf{x};~\boldsymbol{\Theta})^{\mathbf{y}} \mathbf{p}(y_i=0|\mathbf{x};~\boldsymbol{\Theta})^{1-\mathbf{y}}\\
        &amp;= \sigma(\mathbf{x};~\boldsymbol{\Theta})^{\mathbf{y}} \left(1 - \sigma(\mathbf{x};~\boldsymbol{\Theta}) \right)^{1-\mathbf{y}}.
    \end{aligned}
\end{equation}</div>

<details class="warning" open="open"><summary>注意</summary><p>这里<span><span class="MathJax_Preview">\mathbf{x}^{\mathbf{y}}</span><script type="math/tex">\mathbf{x}^{\mathbf{y}}</script></span>表示的是对每个元素一一求取指数，即函数第i个元素的返回值应当为<span><span class="MathJax_Preview">{x_i}^{y_i}</span><script type="math/tex">{x_i}^{y_i}</script></span>。</p>
</details>
<p>我们使用真实值<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>作为指数给概率向量加权。当<span><span class="MathJax_Preview">\mathbf{y}=1</span><script type="math/tex">\mathbf{y}=1</script></span>时，以预测值为1的可信度作为概率；反之则以预测值为0的可信度作为概率。这就是最大似然估计方法。至此，我们可以写出似然估计函数</p>
<div class="overflow">\begin{align}
    L(\boldsymbol{\Theta}) = \mathbf{p}(\mathbf{y}^{(k)}|\mathbf{x}^{(k)};~\boldsymbol{\Theta}).
\end{align}</div>

<p>对似然估计函数取对数，则有</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        l(\boldsymbol{\Theta}) &amp;= \sum_{k=1}^N \log \left( \mathbf{p}(\mathbf{y}^{(k)}|\mathbf{x}^{(k)};~\boldsymbol{\Theta}) \right) \\
        &amp;= \sum_{k=1}^N \mathbf{y}^{(k)} \cdot \log\left(\sigma(\mathbf{x}^{(k)};~\boldsymbol{\Theta})\right) + \left(1 - \mathbf{y}^{(k)} \right) \cdot \log\left(1 - \sigma(\mathbf{x}^{(k)};~\boldsymbol{\Theta})\right).
    \end{aligned}
\end{equation}</div>

<p>我们最终的目的是要最大化似然函数，亦即<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b} = \arg\max\limits_{\boldsymbol{\Theta}} l(\boldsymbol{\Theta})</span><script type="math/tex">\mathbf{W},~\mathbf{b} = \arg\max\limits_{\boldsymbol{\Theta}} l(\boldsymbol{\Theta})</script></span>，这等价于最小化<span><span class="MathJax_Preview">-l(\boldsymbol{\Theta})</span><script type="math/tex">-l(\boldsymbol{\Theta})</script></span>。对比<a href="#mjx-eqn-7"><span><span class="MathJax_Preview">(7)</span><script type="math/tex">(7)</script></span></a>和<a href="#mjx-eqn-8"><span><span class="MathJax_Preview">(8)</span><script type="math/tex">(8)</script></span></a>，于是我们可以定义交叉熵为</p>
<div class="overflow">\begin{align}
   \mathcal{L} \left( \mathbf{y},~ \tilde{\mathbf{y}} \right) = \mathbf{y} \cdot \log\left( \tilde{\mathbf{y}} \right) + \left(1 - \mathbf{y} \right) \cdot \log\left(1 - \tilde{\mathbf{y}} \right).
\end{align}</div>

<p>若我们记<span><span class="MathJax_Preview">\tilde{\mathbf{y}} = \sigma(\tilde{\mathbf{x}})</span><script type="math/tex">\tilde{\mathbf{y}} = \sigma(\tilde{\mathbf{x}})</script></span>，代入sigmoid函数，为了确保该损失函数的稳定性，我们可以将<a href="#mjx-eqn-13"><span><span class="MathJax_Preview">(13)</span><script type="math/tex">(13)</script></span></a>整理为</p>
<div class="overflow">\begin{align}
   \mathcal{L} \left( \mathbf{y},~ \tilde{\mathbf{x}} \right) = \max(\tilde{\mathbf{x}}, \mathbf{0}) - \tilde{\mathbf{x}} \cdot \mathbf{y} + \log\left(1 + e^{-|\tilde{\mathbf{x}}|} \right).
\end{align}</div>

<details class="tip" open="open"><summary>提示</summary><p>这里交叉熵整理的推导过程参见<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">Tensorflow-API官方文档</a>。</p>
</details>
<p>实际情况下，我们使用<a href="#mjx-eqn-14"><span><span class="MathJax_Preview">(14)</span><script type="math/tex">(14)</script></span></a>来求取sigmoid函数激活下的交叉熵。</p>
<h2 id="_7">解线性多分类问题<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h2>
<h3 id="_8">代码规范<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h3>
<p>建立一个具有较强可读性的Tensorflow工程需要我们活用python的模块化设计。我们通常推荐以下的结构</p>
<div class="codehilite"><pre><span></span>.
├─ data/           <span class="c1"># where we store our data</span>
│  └─ ...
├─ tools.py        <span class="c1"># codes for post-processing and analyzing records.</span>
├─ extension.py    <span class="c1"># codes for extending the tensorflow model.</span>
├─ dparser.py      <span class="c1"># data parser</span>
└─ main.py         <span class="c1"># main module where we define our tensorflow model.</span>
</pre></div>

<p>除了保存数据的文件夹，我们应当有三个子模块。其中</p>
<ul>
<li><code>tool</code>: 用来处理、分析生成的数据，通常与Tensorflow无关；</li>
<li><code>extension</code>: 用来扩展tensorflow，例如在这里自定义网络层和操作符；</li>
<li><code>dparser</code>: 数据处理器，用来读取并预处理送入网络的数据；</li>
<li><code>main</code>: 主模块，只定义跟Tensorflow模型有关的内容，需要引用<code>extension</code>和<code>dparser</code>。</li>
</ul>
<p>视情况可以灵活调整结构，但建议将定义Tensorflow模型的代码单独放在主模块里，和其他外围代码分离。</p>
<p>撰写各个模块时，建议使用类封装各组功能相同的函数。具有良好使用习惯的coder应当注意给各个面向用户的类、函数撰写（哪怕简短的）说明文字，在一些较长的函数、方法的定义中，适当注释各部分的功能，以便读者能正确理解代码意义。</p>
<p>另外，在对象命名上，python有如下必须遵守或不成文的规定，和C/C++用户熟悉的蛇形命名法不同，它大致包括</p>
<ul>
<li>类与函数多用驼峰命名法，变量可以采用驼峰或蛇形命名法。<ul>
<li>驼峰命名法指的是用大小写区分每个单词块，例如<code class="codehilite"><span class="n">alphaBetaFunction</span><span class="p">()</span></code>；</li>
<li>蛇形命名法指的是用下划线区分每个单词块，例如<code class="codehilite"><span class="n">alpha_beta_function</span> <span class="o">=</span> <span class="mi">10</span></code>；</li>
</ul>
</li>
<li>宏变量使用全字大写+蛇形命名法</li>
<li>函数/方法，还有模块均是首字母小写，但类的首字母大写。</li>
<li>用单下划线<code>_</code>表示临时存储器，或省略参数，例如一个函数<code class="codehilite"><span class="n">func</span><span class="p">()</span></code>有两个返回值时，可以用<code class="codehilite"><span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">func</span><span class="p">()</span></code>表示我们只需要第二个返回值；单下划线还可以与星号连用省略多个返回值；</li>
<li>以单下划线开头的方法，表示模块级的私有方法，在模块以外使用<code class="codehilite"><span class="kn">import</span></code>导入类时，不会导入这些方法，例如<code class="codehilite"><span class="k">def</span> <span class="nf">_alphaBeta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span></code>；</li>
<li>以单下划线结尾的对象，用来和python的关键字区分，例如<code class="codehilite"><span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">class_</span><span class="p">)</span></code>;</li>
<li>以双下划线开头的方法，如果不以双下划线结尾，则表示类级的私有方法，只有类内部的方法能调用这些方法，在类外部、包括继承的子类里都原则上不能调用（但其实也有办法调用），例如<code class="codehilite"><span class="k">def</span> <span class="nf">_alphaBeta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span></code>；</li>
<li>以双下划线同时开头和结尾的方法，一般是用来<span></span><strong>重写 (override)</strong><span></span>特殊功能，例如<code class="codehilite"><span class="k">def</span> <span class="fm">__getattribute__</span><span class="p">():</span></code>将重写获得类属性的方法。</li>
</ul>
<h3 id="_9">数据生成<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h3>
<p>在本项目里，我们不需要扩展Tensorflow。但是，我们需要以随机生成数据代替数据集。因此，首先，通过以下代码定义数据生成器</p>
<div class="superfences-tabs">
<input name="__tabs_2" type="radio" id="__tab_2_0" checked="checked" />
<label for="__tab_2_0">dparser.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TestDataSet</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A generator of the data set for testing the linear model.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale_x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Initialize the data generator.</span>
<span class="sd">        scale_x: the scale of input vector.</span>
<span class="sd">        A, c: the linear transformation.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">scale_x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Configuration</span>
<span class="sd">        train: a flag for controlling the iterator mode.</span>
<span class="sd">        batch: the number of samples in a batch</span>
<span class="sd">        noise: std. of the error added to the y.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>

    <span class="k">def</span> <span class="nf">next_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Get the next train batch: (x, y)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span><span class="p">])</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">&gt;</span> <span class="mf">1e-3</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">next_test</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Get the next test batch x.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span><span class="p">])</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">samp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__next__</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">samp</span>

    <span class="k">def</span> <span class="nf">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_train</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_test</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
</div>
<p>该生成器输入一组<span><span class="MathJax_Preview">\mathbf{A},~\mathbf{c}</span><script type="math/tex">\mathbf{A},~\mathbf{c}</script></span>，以及相关配置，之后就可以通过<span></span><strong>迭代器 (iterator)</strong><span></span>或<span></span><strong>方法 (method)</strong><span></span>随机生成数据。这种数据集写法我们在后面还会用到，<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></code>允许我们不是馈入样本（或样本批次），而是馈入一个<span></span><strong>生成器(generator)</strong><span>。因此我们重写了<code class="codehilite"><span class="fm">__iter__</span></code>方法，并使其通过<code>yield</code>返回一个生成器。这样我们定义的数据集类就可以被Keras的训练函数<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></code>使用。接下来，调用如下测试代码：</p>
<div class="superfences-tabs">
<input name="__tabs_3" type="radio" id="__tab_3_0" checked="checked" />
<label for="__tab_3_0">dparser.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">test_dataset</span><span class="p">():</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
        <span class="n">dataSet</span> <span class="o">=</span> <span class="n">TestDataSet</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">dIter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dIter</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span>

<span class="n">test_dataset</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_3" type="radio" id="__tab_3_1" />
<label for="__tab_3_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span><span class="p">[</span><span class="mf">0.47</span> <span class="mf">0.57</span> <span class="mf">0.58</span> <span class="mf">0.56</span> <span class="mf">0.5</span>  <span class="mf">0.38</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.6</span>  <span class="mf">0.61</span> <span class="mf">0.47</span> <span class="mf">0.48</span> <span class="mf">0.38</span> <span class="mf">0.52</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.5</span>  <span class="mf">0.61</span> <span class="mf">0.49</span> <span class="mf">0.42</span> <span class="mf">0.45</span> <span class="mf">0.53</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.59</span> <span class="mf">0.52</span> <span class="mf">0.44</span> <span class="mf">0.44</span> <span class="mf">0.49</span> <span class="mf">0.51</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.54</span> <span class="mf">0.59</span> <span class="mf">0.48</span> <span class="mf">0.5</span>  <span class="mf">0.51</span> <span class="mf">0.47</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.49</span> <span class="mf">0.57</span> <span class="mf">0.56</span> <span class="mf">0.49</span> <span class="mf">0.53</span> <span class="mf">0.4</span> <span class="p">]</span>
<span class="p">[</span><span class="mf">0.5</span>  <span class="mf">0.61</span> <span class="mf">0.51</span> <span class="mf">0.54</span> <span class="mf">0.51</span> <span class="mf">0.52</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.5</span>  <span class="mf">0.51</span> <span class="mf">0.61</span> <span class="mf">0.5</span>  <span class="mf">0.44</span> <span class="mf">0.5</span> <span class="p">]</span>
<span class="p">[</span><span class="mf">0.44</span> <span class="mf">0.46</span> <span class="mf">0.53</span> <span class="mf">0.45</span> <span class="mf">0.56</span> <span class="mf">0.52</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.52</span> <span class="mf">0.46</span> <span class="mf">0.51</span> <span class="mf">0.52</span> <span class="mf">0.49</span> <span class="mf">0.44</span><span class="p">]</span>
</pre></div></div>
</div>
<p>我们随机生成了<span><span class="MathJax_Preview">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</span><script type="math/tex">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</script></span>的数据，每组数据100个，并且测试了10组。输出结果是各组测试中，<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>在对应维度上分类为1的概率估计。结果基本都在0.5左右，说明我们的这种数据生成模式产生的点能均匀分布在各个超平面两侧，适合进行后续测试。</p>
<h3 id="_10">定义线性顺序模型<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<p><span></span><strong>顺序(sequential)</strong><span></span>模型是一个单输入单输出模型，网络结构较为简单，也不存在跨层短接（残差连接）。在大多数情况下，已经上手的Tensorflow用户不使用这个模型，故而作为我们入门的第一个project，我们姑且用之，但我们将不再使用顺序模型来实现后续的project。一个顺序模型大致可以描述为下图的模式：</p>
<div class="mermaid">graph LR
st(输&lt;br/&gt;入) --&gt; l1[层&lt;br/&gt;1]
l1 --&gt; l2[层&lt;br/&gt;2]
l2 --&gt; l3[层&lt;br/&gt;3]
l3 --&gt; ldots[层&lt;br/&gt;...]
ldots --&gt; ed(输&lt;br/&gt;出)

classDef styStart fill:#FAE6A9,stroke:#BA9132;
class st,ed styStart</div>

<p>由于我们完成的是一个线性分类器，故而我们使用单层的序列模型即可。</p>
<p>接下来，我们来定义一个类，<code class="codehilite"><span class="k">class</span> <span class="nc">LinClsHandle</span><span class="p">:</span></code>。定义一个类的时候，我们通常需要定义的内容包括</p>
<ul>
<li>在初始化方法<code class="codehilite"><span class="fm">__init__</span></code>里定义传入网络的固定参数，例如学习速率，存取路径等；</li>
<li>在方法<code class="codehilite"><span class="n">construct</span></code>里定义网络的构造和使用的优化器；</li>
<li>在方法<code class="codehilite"><span class="n">train</span></code>里定义训练网络的过程，主要需要调用<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></code>。如果我们在数据集的定义非常完善，则这一环节不需要花费太多的功夫；</li>
<li>在方法<code class="codehilite"><span class="n">test</span></code>里定义测试网络的过程，主要需要调用<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span></code>。如果有必要，可以通过<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">predict</span></code>返回测试结果。</li>
</ul>
<h4 id="_11">初始化方法<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<p>首先，定义初始化方法：</p>
<div class="superfences-tabs">
<input name="__tabs_4" type="radio" id="__tab_4_0" checked="checked" />
<label for="__tab_4_0">lin-cls.py: class LinClsHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">steppe</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Initialization and pass fixed parameters.</span>
<span class="sd">            learning_rate: the learning rate for optimizer.</span>
<span class="sd">            epoch:         training epochs.</span>
<span class="sd">            steppe:        steps per epoch</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steppe</span> <span class="o">=</span> <span class="n">steppe</span>
</pre></div>
</td></tr></table></div>
</div>
<p>由于目前我们的project还非常简单，这里只需要有学习速率(<code>learning_rate</code>)，轮次数(<code>epoch</code>)和每轮迭代次数(<code>steppe</code>)即可。</p>
<h4 id="_12">构造方法<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<p>接下来定义网络构造</p>
<div class="superfences-tabs">
<input name="__tabs_5" type="radio" id="__tab_5_0" checked="checked" />
<label for="__tab_5_0">lin-cls.py: class LinClsHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Construct a linear model and set the optimizer as Adam</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Construction</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">LABEL_SHAPE</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">INPUT_SHAPE</span><span class="p">,),</span> 
                                <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomNormal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">10.0</span><span class="p">),</span> 
                                <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> 
                                <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">)</span>

    <span class="c1"># Set optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="p">]</span>
    <span class="p">)</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y_true</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))))</span>
</pre></div>
</td></tr></table></div>
</div>
<details class="info" open="open"><summary>须知</summary><p>这里<code>LABEL_SHAPE</code>和<code>INPUT_SHAPE</code>为两个宏变量，分别为输出和输入的向量维度。</p>
</details>
<p>我们使用<code>Dense</code>定义全连接层，它的用法请参照<a href="https://keras-zh.readthedocs.io/layers/core/#dense">这里</a>。由于我们已经知道<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>和<span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>可能的取值范围，这里我们重定义了<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>和<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>的初始化方式。</p>
<p>另外，注意我们这里构造网络的时候有如下技巧：</p>
<ul>
<li>我们定义的网络输出是<span><span class="MathJax_Preview">\mathbf{W}\mathbf{x} + \mathbf{b}</span><script type="math/tex">\mathbf{W}\mathbf{x} + \mathbf{b}</script></span>，而非<span><span class="MathJax_Preview">\sigma(\mathbf{W}\mathbf{x} + \mathbf{b})</span><script type="math/tex">\sigma(\mathbf{W}\mathbf{x} + \mathbf{b})</script></span>。这是因为我们需要通过还未被激活的输出用来计算sigmoid交叉熵，亦即式<a href="#mjx-eqn-14"><span><span class="MathJax_Preview">(14)</span><script type="math/tex">(14)</script></span></a>；</li>
<li>我们通过静态方法，直接调用Tensorflow自带的<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">sigmoid交叉熵</a>函数来作为Keras模型的损失函数<code>self..loss</code>；</li>
<li>我们通过静态方法，调用Keras的后端API，自己定义了预测准确度的测度函数<code>self.accuracy</code>；</li>
<li>我们将网络层的关键字<code>self.dense1</code>保留在了实例中，这是为了确保接下来我们能通过实例抽取该层的参数。</li>
</ul>
<p>之所以煞费周折地进行这些处理，盖因为Keras的内建API里目前还没有提供对互不相斥的多分类的支持。例如，无论是<code>tf.keras.metrics.categorical_accuracy</code>还是<code>tf.keras.metrics.categorical_crossentropy</code>，都要求分类的真实值为one-hot类型的向量组，因而它们只适合用在softmax分类器上。为了解决这一问题，我们自己实现了sigmoid分类器。</p>
<h4 id="_13">训练和测试方法<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h4>
<p>最后定义的式训练和测试方法。由于我们目前的project还比较简单，关于这两部分都直接调用现有的API即可。使用的API在之前已经说明。<code>model.fit</code>在没有额外设置的情况下，默认会返回一个<a href="https://keras-zh.readthedocs.io/callbacks/#history">History回调器</a>；<code>model.evaluate</code>返回的是测试样本给出的损失函数和准确值测度。<code>model.predict</code>返回的是测试样本给出的网络输出。详情请参照<a href="https://keras-zh.readthedocs.io/models/sequential/">顺序模型API</a>。</p>
<div class="superfences-tabs">
<input name="__tabs_6" type="radio" id="__tab_6_0" checked="checked" />
<label for="__tab_6_0">lin-cls.py: class LinClsHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataSet</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Use a data set to train the network.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">steppe</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Use (data, label) pairs to test the results.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">accu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Evaluated loss     =&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Evaluated accuracy =&#39;</span><span class="p">,</span> <span class="n">accu</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<h3 id="_14">调试<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h3>
<p>首先，训练网络。我们随机生成<span><span class="MathJax_Preview">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</span><script type="math/tex">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</script></span>的线性变换，并且设置好数据集，给定噪声扰动为<span><span class="MathJax_Preview">\boldsymbol{\varepsilon} \sim \mathcal{N}(0,1)^6</span><script type="math/tex">\boldsymbol{\varepsilon} \sim \mathcal{N}(0,1)^6</script></span>。设定20个epoch，每个epoch迭代500次，每次馈入32个样本构成的batch，然后开始训练：</p>
<div class="superfences-tabs">
<input name="__tabs_7" type="radio" id="__tab_7_0" checked="checked" />
<label for="__tab_7_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="n">INPUT_SHAPE</span><span class="p">,</span> <span class="n">LABEL_SHAPE</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">LABEL_SHAPE</span><span class="p">])</span>
<span class="n">dataSet</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">TestDataSet</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># Construct the model and train it.</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">LinClsHandle</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">steppe</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">h</span><span class="o">.</span><span class="n">construct</span><span class="p">()</span>
<span class="n">record</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_7" type="radio" id="__tab_7_1" />
<label for="__tab_7_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span>Epoch <span class="m">1</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 3s 5ms/step - loss: <span class="m">48</span>.2269 - accuracy: <span class="m">0</span>.5458
Epoch <span class="m">2</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">25</span>.5149 - accuracy: <span class="m">0</span>.6491
Epoch <span class="m">3</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">11</span>.9822 - accuracy: <span class="m">0</span>.7607
Epoch <span class="m">4</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">5</span>.6580 - accuracy: <span class="m">0</span>.8513
Epoch <span class="m">5</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">2</span>.7230 - accuracy: <span class="m">0</span>.9106
Epoch <span class="m">6</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">1</span>.1082 - accuracy: <span class="m">0</span>.9462
Epoch <span class="m">7</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.3278 - accuracy: <span class="m">0</span>.9708
Epoch <span class="m">8</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 3ms/step - loss: <span class="m">0</span>.0618 - accuracy: <span class="m">0</span>.9878
Epoch <span class="m">9</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0149 - accuracy: <span class="m">0</span>.9963
Epoch <span class="m">10</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0121 - accuracy: <span class="m">0</span>.9979
Epoch <span class="m">11</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0124 - accuracy: <span class="m">0</span>.9976
Epoch <span class="m">12</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0121 - accuracy: <span class="m">0</span>.9978
Epoch <span class="m">13</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0121 - accuracy: <span class="m">0</span>.9973
Epoch <span class="m">14</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0120 - accuracy: <span class="m">0</span>.9974
Epoch <span class="m">15</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0121 - accuracy: <span class="m">0</span>.9970
Epoch <span class="m">16</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0116 - accuracy: <span class="m">0</span>.9971
Epoch <span class="m">17</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0120 - accuracy: <span class="m">0</span>.9967
Epoch <span class="m">18</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 3ms/step - loss: <span class="m">0</span>.0114 - accuracy: <span class="m">0</span>.9971
Epoch <span class="m">19</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0114 - accuracy: <span class="m">0</span>.9969
Epoch <span class="m">20</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0113 - accuracy: <span class="m">0</span>.9970
</pre></div></div>
</div>
<p>接下来，从训练返回的<code>History</code>类型的回调器中抽取对loss和accuracy的记录。</p>
<div class="superfences-tabs">
<input name="__tabs_8" type="radio" id="__tab_8_0" checked="checked" />
<label for="__tab_8_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">showCurve</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Cross entropy&#39;</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">showCurve</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_8" type="radio" id="__tab_8_1" />
<label for="__tab_8_1">Output</label>
<div class="superfences-content"><div class="overflow"><p><img alt="交叉熵损失函数" class="img-fluid" src="../../../assets/images/book-1-x/lincls-loss.svg" tag="2" title="交叉熵损失函数"></p>
<p><img alt="准确度测度" class="img-fluid" src="../../../assets/images/book-1-x/lincls-accu.svg" tag="2" title="准确度测度"></p></div></div>
</div>
<p>重新设定数据集的产生方式，变为每个batch含10个样本。使用这组重新随机生成的数据测试网络输出，</p>
<div class="superfences-tabs">
<input name="__tabs_9" type="radio" id="__tab_9_0" checked="checked" />
<label for="__tab_9_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Generate a group of testing samples:</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>

<span class="c1"># Check the testing results</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;True class&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Predicted class&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_9" type="radio" id="__tab_9_1" />
<label for="__tab_9_1">Output</label>
<div class="superfences-content"><div class="overflow"><p><img alt="y测量值效果" class="img-fluid" src="../../../assets/images/book-1-x/lincls-res.png" tag="3" title="y测量值效果"></p></div></div>
</div>
<p>注意我们未对测量的结果阈值化，因此显示出来的测量结果和理想值略有差别，但从图可知，阈值化后则测量结果全部准确。</p>
<p>通过抽取<code>h.dense1</code>的参数，我们可以对比<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>和<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>，以及<span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>和<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>，</p>
<div class="superfences-tabs">
<input name="__tabs_10" type="radio" id="__tab_10_0" checked="checked" />
<label for="__tab_10_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Check the regressed values</span>
<span class="n">W</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">dense1</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(),</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(),</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;W&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_10" type="radio" id="__tab_10_1" />
<label for="__tab_10_1">Output</label>
<div class="superfences-content"><div class="overflow"><p><img alt="真实线性变换矩阵A" class="img-fluid" src="../../../assets/images/book-1-x/lincls-A.png" tag="4" title="真实线性变换矩阵A"></p>
<p><img alt="训练得到的线性变换矩阵W" class="img-fluid" src="../../../assets/images/book-1-x/lincls-W.png" tag="4" title="训练得到的线性变换矩阵W"></p>
<p><img alt="对比偏置c, b" class="img-fluid" src="../../../assets/images/book-1-x/lincls-cb.svg" tag="4" title="对比偏置c, b"></p></div></div>
</div>
<p>可以发现，虽然我们训练的分类器十分有效，但其权值和预期的<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>, <span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>并不相同。这是由于我们训练的样本加入了噪声。这种技术常用于神经网络的训练，被认为是一种提高鲁棒性、减小过拟合、避免不稳定解的一个有效手段。可以看出真实值<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>存在偏高值，但<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>的数值更加均匀。</p>
                
                  
                    <h2 id="__source">来源</h2>
                    
                    
                    
                    
                    <a href="https://github.com/cainmagi/tensorflow-guide/tree//1-1-linear-classification" title="1-1-linear-classification" class="md-source-file">
                      1-1-linear-classification
                    </a>
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://cainmagi.github.io/tensorflow-guide/book-1-x/chapter-1/linear-classification/";
      this.page.identifier =
        "book-1-x/chapter-1/linear-classification/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//tensorflow-guide.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../hello-world/" title="Hello world!" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                Hello world!
              </span>
            </div>
          </a>
        
        
          <a href="../../../release-notes/" title="更新记录" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                更新记录
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Yuchen Jin
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../../assets/fonts/font-awesome.css">
    
      <a href="https://cainmagi.github.io/" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="mailto:cainmagi@gmail.com" class="md-footer-social__link fa fa-envelope"></a>
    
      <a href="https://github.com/cainmagi" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/squidfunk" class="md-footer-social__link fa fa-steam"></a>
    
      <a href="https://weibo.com/u/5885093621" class="md-footer-social__link fa fa-weibo"></a>
    
      <a href="https://www.youtube.com/channel/UCzqpNK5qFMy5_cI1i0Z1nQw" class="md-footer-social__link fa fa-youtube-play"></a>
    
      <a href="https://music.163.com/#/user/home?id=276304206" class="md-footer-social__link fa fa-music"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.43ad2ac2.js"></script>
      
        
        
          
          <script src="../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js"></script>
      
        <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
      
        <script src="../../../javascripts/simpleLightbox.min.js"></script>
      
        <script src="../../../javascripts/extensions.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>