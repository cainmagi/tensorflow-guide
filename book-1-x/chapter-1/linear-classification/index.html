



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="本节介绍如何使用顺序模型(sequential model)来编写一个线性分类器，使用sigmoid函数激活，并验证其效果。在本节我们将编写第一个Project，并介绍一些基本概念、和一个推荐的Tensorflow Project的编写格式。">
      
      
        <link rel="canonical" href="https://cainmagi.github.io/tensorflow-guide/book-1-x/chapter-1/linear-classification/">
      
      
        <meta name="author" content="Yuchen Jin (cainmagi)">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../../assets/images/icons/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>线性分类 - Tensorflow手札</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.982221ab.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#ff7043">
      
    
    
      <script src="../../../assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,400,400i,600,700,900|Roboto+Mono">
        <style>body,input{font-family:"Noto Serif SC","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../../stylesheets/main.css">
    
      <link rel="stylesheet" href="../../../stylesheets/extensions.css">
    
      <link rel="stylesheet" href="../../../stylesheets/simpleLightbox.min.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-119875813-2", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="deep-orange" data-md-color-accent="orange">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://cainmagi.github.io/tensorflow-guide/" title="Tensorflow手札" class="md-header-nav__button md-logo">
          
            <img src="../../../assets/images/icons/Tensorflow.svg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Tensorflow手札
            </span>
            <span class="md-header-nav__topic">
              线性分类
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/cainmagi/tensorflow-guide" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    cainmagi/tensorflow-guide
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../.." title="TF 1.x" class="md-tabs__link md-tabs__link--active">
          TF 1.x
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://cainmagi.github.io/tensorflow-guide/" title="Tensorflow手札" class="md-nav__button md-logo">
      
        <img src="../../../assets/images/icons/Tensorflow.svg" width="48" height="48">
      
    </a>
    Tensorflow手札
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/cainmagi/tensorflow-guide" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    cainmagi/tensorflow-guide
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1" checked>
    
    <label class="md-nav__link" for="nav-1">
      TF 1.x
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        TF 1.x
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../.." title="扉页" class="md-nav__link">
      扉页
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-2" type="checkbox" id="nav-1-2" checked>
    
    <label class="md-nav__link" for="nav-1-2">
      从线性问题入门
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-2">
        从线性问题入门
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="本章总说" class="md-nav__link">
      本章总说
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../hello-world/" title="Hello world!" class="md-nav__link">
      Hello world!
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        线性分类
      </label>
    
    <a href="./" title="线性分类" class="md-nav__link md-nav__link--active">
      线性分类
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="理论" class="md-nav__link">
    理论
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="感知机" class="md-nav__link">
    感知机
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" title="Sigmoid函数" class="md-nav__link">
    Sigmoid函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="求解问题" class="md-nav__link">
    求解问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" title="交叉熵" class="md-nav__link">
    交叉熵
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="解线性多分类问题" class="md-nav__link">
    解线性多分类问题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="代码规范" class="md-nav__link">
    代码规范
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow" title="Tensorflow的数据概念" class="md-nav__link">
    Tensorflow的数据概念
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="数据生成" class="md-nav__link">
    数据生成
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="定义线性顺序模型" class="md-nav__link">
    定义线性顺序模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="初始化方法" class="md-nav__link">
    初始化方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="构造方法" class="md-nav__link">
    构造方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="训练和测试方法" class="md-nav__link">
    训练和测试方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" title="调试" class="md-nav__link">
    调试
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
        <li class="md-nav__item">
          <a href="#__source" title="来源" class="md-nav__link md-nav__link--active">
            来源
          </a>
        </li>
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../linear-regression/" title="线性回归" class="md-nav__link">
      线性回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../nonlinear-regression/" title="非线性回归" class="md-nav__link">
      非线性回归
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../release-notes/" title="更新记录" class="md-nav__link">
      更新记录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../licenses/" title="协议" class="md-nav__link">
      协议
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="理论" class="md-nav__link">
    理论
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="问题描述" class="md-nav__link">
    问题描述
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="感知机" class="md-nav__link">
    感知机
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sigmoid" title="Sigmoid函数" class="md-nav__link">
    Sigmoid函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="求解问题" class="md-nav__link">
    求解问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" title="交叉熵" class="md-nav__link">
    交叉熵
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" title="解线性多分类问题" class="md-nav__link">
    解线性多分类问题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="代码规范" class="md-nav__link">
    代码规范
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorflow" title="Tensorflow的数据概念" class="md-nav__link">
    Tensorflow的数据概念
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" title="数据生成" class="md-nav__link">
    数据生成
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="定义线性顺序模型" class="md-nav__link">
    定义线性顺序模型
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_11" title="初始化方法" class="md-nav__link">
    初始化方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="构造方法" class="md-nav__link">
    构造方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="训练和测试方法" class="md-nav__link">
    训练和测试方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" title="调试" class="md-nav__link">
    调试
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
        <li class="md-nav__item">
          <a href="#__source" title="来源" class="md-nav__link md-nav__link--active">
            来源
          </a>
        </li>
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="_1">线性分类<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">摘要</p>
<p>本节介绍如何使用顺序模型(sequential model)来编写一个线性分类器，使用sigmoid函数激活，并验证其效果。在本节我们将编写第一个Project，并介绍一些基本概念、和一个推荐的Tensorflow Project的编写格式。</p>
</div>
<h2 id="_2">理论<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="_3">问题描述<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>考虑我们有如下的二分类数据集<span><span class="MathJax_Preview">(\mathbf{x},~y_i) \in \mathbb{D}_i</span><script type="math/tex">(\mathbf{x},~y_i) \in \mathbb{D}_i</script></span>，并且有一个未知的常数向量<span><span class="MathJax_Preview">\mathbf{a}_i</span><script type="math/tex">\mathbf{a}_i</script></span>和未知的常数标量<span><span class="MathJax_Preview">c_i</span><script type="math/tex">c_i</script></span>，使得：</p>
<div class="overflow">\begin{equation}
    y_i = \left\{
    \begin{aligned}
        0, &amp;&amp; \mathbf{a}_i^T \mathbf{x} + c_i \leqslant 0, \\
        1, &amp;&amp; \mathbf{a}_i^T \mathbf{x} + c_i &gt; 0.
    \end{aligned}
    \right.
\end{equation}</div>

<p>其中，<span><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>可以看成是某超平面的（未标准化的）法向量，那么<span><span class="MathJax_Preview">\mathbf{a}^T \mathbf{x} + c = 0</span><script type="math/tex">\mathbf{a}^T \mathbf{x} + c = 0</script></span>是该超平面的截距式定义，亦即该平面与<span><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span>轴的交点可以显式表述为<span><span class="MathJax_Preview">x_i^{(0)} = - \frac{c}{a_i}</span><script type="math/tex">x_i^{(0)} = - \frac{c}{a_i}</script></span>。由此可知，式<a href="#mjx-eqn-1"><span><span class="MathJax_Preview">(1)</span><script type="math/tex">(1)</script></span></a>显式定义了一个点在超平面的哪一侧。特别地，若<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>是一个二维向量，则该超平面退化为一维平面；若<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>是一个标量，则该超平面退化为一条直线。</p>
<p>若我们定义<span><span class="MathJax_Preview">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</script></span>，有</p>
<div class="overflow">\begin{equation}
    \mathbf{y} =
    \begin{bmatrix}
      y_1 \\
      y_2 \\
      \vdots \\
      y_n
    \end{bmatrix}, ~~
    \mathbf{A} = 
    \begin{bmatrix}
      \mathbf{a}^T_1 \\
      \mathbf{a}^T_2 \\
      \vdots \\
      \mathbf{a}^T_n
    \end{bmatrix}, ~~
    \mathbf{c} = 
    \begin{bmatrix}
      c_1 \\
      c_2 \\
      \vdots \\
      c_n
    \end{bmatrix}.
\end{equation}</div>

<p>则我们可以认为</p>
<div class="overflow">\begin{align}
   \mathbf{y} = \left\{ \begin{bmatrix}\hat{y}_1 &gt; 0 &amp; \hat{y}_2 &gt; 0 &amp; \cdots &amp; \hat{y}_n &gt; 0\end{bmatrix}^T, ~ \left| ~ \hat{\mathbf{y}} = \mathbf{A} \mathbf{x} + \mathbf{c} + \boldsymbol{\varepsilon} \right. \right\},
\end{align}</div>

<p>其中<span><span class="MathJax_Preview">\boldsymbol{\varepsilon}</span><script type="math/tex">\boldsymbol{\varepsilon}</script></span>是一个定义噪声的向量。</p>
<p>我们可以把向量<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>的元素看成是互不相关的多个超平面对向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>各自独立的分类结果。即<span><span class="MathJax_Preview">y_i = \{ \hat{y}_i&gt;0 ~ | ~ \hat{y}_i = \mathbf{a}_i^T \mathbf{x} + c_i + \varepsilon_i \}</span><script type="math/tex">y_i = \{ \hat{y}_i>0 ~ | ~ \hat{y}_i = \mathbf{a}_i^T \mathbf{x} + c_i + \varepsilon_i \}</script></span>。由于每个超平面构成一个二分类，如果把每个二分类看作是向量是否属于这个类的测度，那么<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>可以被看作是一个多分类的结果，尽管向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>可能被同时分入多个类中。</p>
<p>假设我们的数据集<span><span class="MathJax_Preview">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x},~\mathbf{y}) \in \mathbb{D}</script></span>符合<a href="#mjx-eqn-3"><span><span class="MathJax_Preview">(3)</span><script type="math/tex">(3)</script></span></a>定义的数据分布特征。我们的基本要求是，在我们不知道<span><span class="MathJax_Preview">\mathbf{A},~\mathbf{c}</span><script type="math/tex">\mathbf{A},~\mathbf{c}</script></span>的情况下，使用大量<span><span class="MathJax_Preview">(\mathbf{x}^{(k)},~\mathbf{y}^{(k)}) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x}^{(k)},~\mathbf{y}^{(k)}) \in \mathbb{D}</script></span>样本训练一个线性分类器，使得当我们给定任意一个新样本<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>的时候，分类器能推断出其对应的<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>来（亦即是否属于该分类）。</p>
<details class="info" open="open"><summary>须知</summary><p>请注意我们在这里说到“线性分类器”，虽然使用“线性”一词，但准确来说，这是一个仿射变换。因为线性变换要求有齐次性，即<span><span class="MathJax_Preview">f(x) = \alpha f(x)</span><script type="math/tex">f(x) = \alpha f(x)</script></span>，但仿射变换允许我们引入一个平移向量<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>。当然，我们的求解的线性问题本身也是一个仿射变换。</p>
</details>
<p>在这个问题里，我们虽然不知道<span><span class="MathJax_Preview">\mathbf{A},~\mathbf{c}</span><script type="math/tex">\mathbf{A},~\mathbf{c}</script></span>，但我们知道由<a href="#mjx-eqn-3"><span><span class="MathJax_Preview">(3)</span><script type="math/tex">(3)</script></span></a>确定的线性关系，因此，我们可以随机生成一组<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b}</span><script type="math/tex">\mathbf{W},~\mathbf{b}</script></span>，构建线性模型：</p>
<div class="overflow">\begin{align}
   \tilde{\mathbf{y}} = \sigma ( \mathbf{W} \mathbf{x} + \mathbf{b} ).
\end{align}</div>

<p>其中，可微函数<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>是一个将实数空间<span><span class="MathJax_Preview">\mathbb{R}^n</span><script type="math/tex">\mathbb{R}^n</script></span>映射到有限范围的实数空间<span><span class="MathJax_Preview">[0,~1]^n</span><script type="math/tex">[0,~1]^n</script></span>内的函数。特别地，<span><span class="MathJax_Preview">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</span><script type="math/tex">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</script></span>。因此，可以将<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>看作是二分类布尔函数的插值函数。理论上，只要我们找到<span><span class="MathJax_Preview">\mathbf{W}=\mathbf{A}</span><script type="math/tex">\mathbf{W}=\mathbf{A}</script></span>，<span><span class="MathJax_Preview">\mathbf{b}=\mathbf{c}</span><script type="math/tex">\mathbf{b}=\mathbf{c}</script></span>，则该线性分类器可以直接拟合出原分布来。</p>
<h3 id="_4">感知机<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>我们将<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>定义的线性模型称为<span></span><strong>单层感知机 (Single-layer perceptron)</strong><span></span>模型。它包含一个权重矩阵<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>和一个偏置矩阵<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>。事实上，可以将<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>改写成如下形式</p>
<div class="overflow">\begin{align}
   \tilde{\mathbf{y}} = \sigma \left( \begin{bmatrix} \mathbf{W} &amp; \mathbf{b} \end{bmatrix} \begin{bmatrix} \mathbf{x} \\ 1 \end{bmatrix} \right).
\end{align}</div>

<p>可见偏置本身可以看成是输入向量多了一个常数元素的等价模型。</p>
<p>感知机是最早的神经网络形式，它非常孱弱，只能解线性问题，但却为神经网络后来的发展开了先河。在单层感知机里，我们视输入向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>的每个元素为一个“神经元”，矩阵<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>和偏置<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>将我们的输入映射到输出层<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>，输出层的每个元素也视为一个神经元。在这个过程中，<span><span class="MathJax_Preview">W_{ij}</span><script type="math/tex">W_{ij}</script></span>作为<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>行<span><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>列的元素，代表了连接两个神经元的权重。我们用红线代表正值，蓝线代表负值，感知机可以被图示为</p>
<p><img alt="感知机模型" class="img-fluid" src="../../../assets/images/book-1-x/lincls-lp.svg" tag="5" title="感知机模型" /></p>
<p>线性感知机的输出也是输入的线性组合，但我们可以添加激活函数，即<span><span class="MathJax_Preview">\sigma(\cdot)</span><script type="math/tex">\sigma(\cdot)</script></span>将其映射到非线性空间。这要求我们添加的激活函数是一个非线性函数。</p>
<p>事实上，将单层感知机层叠，前一层的输出作为后一层的输入，就构建出早期的神经网络。这种网络每一层都是全连接的（两个神经元之间总是有权重，尽管值可能为0），每一层都有激活函数。理论上，任意一个两层堆叠的感知机，只要神经元数目足够多，就可以拟合出任意一个非线性函数。然而，实际测试中，这一理论的效果并不尽如人意，因此又有陆续地改进，才有了后来的深度学习。饮水思源，鉴往知来，我们也将从这个简简单单的单层模型开始，走上学习“深度学习”之旅。</p>
<h3 id="sigmoid">Sigmoid函数<a class="headerlink" href="#sigmoid" title="Permanent link">&para;</a></h3>
<p>在上述介绍中，我们没有解决的两个问题是，</p>
<ul>
<li>如何定义插值函数<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>？</li>
<li>如何找到合适的<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b}</span><script type="math/tex">\mathbf{W},~\mathbf{b}</script></span>？</li>
</ul>
<p>我们首先讨论第一个问题。一般地，多分类问题中，如果各个分类彼此并非相斥，且不一定要将结果分入任一类的话，我们可以用<span></span><strong>Sigmoid</strong><span></span>函数来定义<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>，亦即</p>
<div class="overflow">\begin{align}
   \sigma(\mathbf{x}) = \frac{1}{ 1 + e^{-\mathbf{x}}}.
\end{align}</div>

<p>它同时满足<span><span class="MathJax_Preview">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</span><script type="math/tex">\sigma(-\infty)=0,~\sigma(0)=0.5,~\sigma(+\infty)=1</script></span>，且是一个单调函数。以下代码向我们展示了这种函数的特性：</p>
<div class="superfences-tabs">
<input name="__tabs_1" type="radio" id="__tab_1_0" checked="checked" />
<label for="__tab_1_0">Python</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">test_sigmoid</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">test_sigmoid</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_1" />
<label for="__tab_1_1">Output</label>
<div class="superfences-content"><div class="overflow"><img alt="Sigmoid函数" class="img-fluid" src="../../../assets/images/book-1-x/lincls-sigmoid.svg" tag="1" title="Sigmoid函数"></div></div>
</div>
<p>使用sigmoid函数的一大好处是，它的导数求解非常简单，很适合用来做神经网络这样一个复杂模型的激活函数。注意虽然<span><span class="MathJax_Preview">\sigma(\mathbf{x})</span><script type="math/tex">\sigma(\mathbf{x})</script></span>和<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>都是向量，这意味着导数是Jacobian矩阵，但由于<span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>是一个对<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>各元素独立的解析函数，这个Jacobian矩阵实际上是一个对角矩阵，对角线上第j个元素的值为</p>
<div class="overflow">\begin{align}
   \left. \frac{ \partial \sigma(x) }{ \partial x } \right|_{x=x_j} = \left. - e^{-x} \left( - \frac{1}{\left( 1+e^{-x} \right)^2} \right) \right|_{x=x_j} = - \sigma(x_j) ( 1 - \sigma(x_j) ).
\end{align}</div>

<p>可见，该函数的导数和计算函数本身的复杂度相若，可以做到快速求导。</p>
<h3 id="_5">求解问题<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>接下来，我们需要解决第二个问题，亦即找到<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b}</span><script type="math/tex">\mathbf{W},~\mathbf{b}</script></span>。这一问题通常可以写成反问题的形式：</p>
<div class="overflow">\begin{align}
   \arg \min_\limits{\mathbf{W},~\mathbf{b}} \sum_{k=1}^N \mathcal{L} \left( \mathbf{y}^{(k)},~ \sigma ( \mathbf{W} \mathbf{x}^{(k)} + \mathbf{b} ) \right).
\end{align}</div>

<p>最简单的情况下，我们可以把<span></span><strong>损失函数(loss function)</strong><span></span>定义为</p>
<div class="overflow">\begin{align}
   \mathcal{L} \left( \mathbf{y},~ \tilde{\mathbf{y}} \right) = \lVert \mathbf{y} - \tilde{\mathbf{y}} \rVert_2^2.
\end{align}</div>

<p>我们称<a href="#mjx-eqn-8"><span><span class="MathJax_Preview">(8)</span><script type="math/tex">(8)</script></span></a>为<span></span><strong>逻辑斯蒂回归(logistic regression)</strong><span></span>。有趣的是，虽然这个术语叫“回归”，但它解的其实是个分类问题。但是，既然这是一个分类问题，我们可以不使用这个损失函数，而是从概率论的角度看待这个问题。由此，我们引出一个新的损失函数：“交叉熵”。</p>
<h3 id="_6">交叉熵<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>我们视sigmoid函数输出的值为一个概率，表示分类器对预测结果的确信程度，记<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b} \in \boldsymbol{\Theta}</span><script type="math/tex">\mathbf{W},~\mathbf{b} \in \boldsymbol{\Theta}</script></span>，则</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \mathbf{p}(y_i=1|\mathbf{x};~\boldsymbol{\Theta}) &amp;= \sigma(\mathbf{x};~\boldsymbol{\Theta}), \\
        \mathbf{p}(y_i=0|\mathbf{x};~\boldsymbol{\Theta}) &amp;= 1 - \sigma(\mathbf{x};~\boldsymbol{\Theta}).
    \end{aligned}
\end{equation}</div>

<p>注意这里的概率向量的含义是，其中第i个元素表明第i个超平面分类结果的<span></span><strong>确信程度</strong><span></span>。</p>
<p>然而，这个概率只是分类器对分类结果的确信程度，却并非是分类准确度的概率，实际上，分类<span></span><strong>准确度</strong><span></span>的概率，应当表述为</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \mathbf{p}(\mathbf{y}|\mathbf{x};~\boldsymbol{\Theta}) &amp;= \mathbf{p}(y_i=1|\mathbf{x};~\boldsymbol{\Theta})^{\mathbf{y}} \mathbf{p}(y_i=0|\mathbf{x};~\boldsymbol{\Theta})^{1-\mathbf{y}}\\
        &amp;= \sigma(\mathbf{x};~\boldsymbol{\Theta})^{\mathbf{y}} \left(1 - \sigma(\mathbf{x};~\boldsymbol{\Theta}) \right)^{1-\mathbf{y}}.
    \end{aligned}
\end{equation}</div>

<details class="warning" open="open"><summary>注意</summary><p>这里<span><span class="MathJax_Preview">\mathbf{x}^{\mathbf{y}}</span><script type="math/tex">\mathbf{x}^{\mathbf{y}}</script></span>表示的是对每个元素一一求取指数，即函数第i个元素的返回值应当为<span><span class="MathJax_Preview">{x_i}^{y_i}</span><script type="math/tex">{x_i}^{y_i}</script></span>。</p>
</details>
<p>我们使用真实值<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>作为指数给概率向量加权。当<span><span class="MathJax_Preview">\mathbf{y}=1</span><script type="math/tex">\mathbf{y}=1</script></span>时，乘积项的第二个因子消去，该函数退化为以预测值为1的可信度<span><span class="MathJax_Preview">\mathbf{p}(y_i=1|\mathbf{x};~\boldsymbol{\Theta})</span><script type="math/tex">\mathbf{p}(y_i=1|\mathbf{x};~\boldsymbol{\Theta})</script></span>；反之则第一个因子消去，退化为以预测值为0的可信度<span><span class="MathJax_Preview">\mathbf{p}(y_i=0|\mathbf{x};~\boldsymbol{\Theta})</span><script type="math/tex">\mathbf{p}(y_i=0|\mathbf{x};~\boldsymbol{\Theta})</script></span>。这就是最大似然估计方法。至此，我们可以写出似然估计函数</p>
<div class="overflow">\begin{align}
    L(\boldsymbol{\Theta}) = \mathbf{p}(\mathbf{y}^{(k)}|\mathbf{x}^{(k)};~\boldsymbol{\Theta}).
\end{align}</div>

<p>对似然估计函数取对数，则有</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        l(\boldsymbol{\Theta}) &amp;= \sum_{k=1}^N \log \left( \mathbf{p}(\mathbf{y}^{(k)}|\mathbf{x}^{(k)};~\boldsymbol{\Theta}) \right) \\
        &amp;= \sum_{k=1}^N \mathbf{y}^{(k)} \cdot \log\left(\sigma(\mathbf{x}^{(k)};~\boldsymbol{\Theta})\right) + \left(1 - \mathbf{y}^{(k)} \right) \cdot \log\left(1 - \sigma(\mathbf{x}^{(k)};~\boldsymbol{\Theta})\right).
    \end{aligned}
\end{equation}</div>

<p>我们最终的目的是要最大化似然函数，亦即<span><span class="MathJax_Preview">\mathbf{W},~\mathbf{b} = \arg\max\limits_{\boldsymbol{\Theta}} l(\boldsymbol{\Theta})</span><script type="math/tex">\mathbf{W},~\mathbf{b} = \arg\max\limits_{\boldsymbol{\Theta}} l(\boldsymbol{\Theta})</script></span>，这等价于最小化<span><span class="MathJax_Preview">-l(\boldsymbol{\Theta})</span><script type="math/tex">-l(\boldsymbol{\Theta})</script></span>。对比<a href="#mjx-eqn-8"><span><span class="MathJax_Preview">(8)</span><script type="math/tex">(8)</script></span></a>和<a href="#mjx-eqn-9"><span><span class="MathJax_Preview">(9)</span><script type="math/tex">(9)</script></span></a>，于是我们可以定义交叉熵为</p>
<div class="overflow">\begin{align}
   \mathcal{L} \left( \mathbf{y},~ \tilde{\mathbf{y}} \right) = - \mathrm{mean}\left[ \mathbf{y} \cdot \log\left( \tilde{\mathbf{y}} \right) + \left(1 - \mathbf{y} \right) \cdot \log\left(1 - \tilde{\mathbf{y}} \right) \right].
\end{align}</div>

<p>注意这里我们使用<span><span class="MathJax_Preview">\mathrm{mean}\left[ \cdot \right]</span><script type="math/tex">\mathrm{mean}\left[ \cdot \right]</script></span>表示求取一个向量所有元素的平均值。实际上，Tensorflow允许我们定义损失函数的输出为一个和输出向量维度相同的向量，Tensorflow自带的交叉熵也是这样定义的。实际应用时，Tensorflow会自动在向量维度上求均值，并压缩成上述<a href="#mjx-eqn-14"><span><span class="MathJax_Preview">(14)</span><script type="math/tex">(14)</script></span></a>的形式。</p>
<p>若我们记<span><span class="MathJax_Preview">\tilde{\mathbf{y}} = \sigma(\tilde{\mathbf{x}})</span><script type="math/tex">\tilde{\mathbf{y}} = \sigma(\tilde{\mathbf{x}})</script></span>，代入sigmoid函数，为了确保该损失函数的稳定性，我们可以将<a href="#mjx-eqn-14"><span><span class="MathJax_Preview">(14)</span><script type="math/tex">(14)</script></span></a>整理为</p>
<div class="overflow">\begin{align}
   \mathcal{L} \left( \mathbf{y},~ \tilde{\mathbf{x}} \right) = \mathrm{mean}\left[ \max(\tilde{\mathbf{x}}, \mathbf{0}) - \tilde{\mathbf{x}} \cdot \mathbf{y} + \log\left(1 + e^{-|\tilde{\mathbf{x}}|} \right)  \right].
\end{align}</div>

<details class="tip" open="open"><summary>提示</summary><p>这里交叉熵整理的推导过程参见<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">Tensorflow-API官方文档</a>。</p>
</details>
<p>实际情况下，我们使用<a href="#mjx-eqn-15"><span><span class="MathJax_Preview">(15)</span><script type="math/tex">(15)</script></span></a>来求取sigmoid函数激活下的交叉熵。</p>
<h2 id="_7">解线性多分类问题<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h2>
<p>接下来，我们将开始实战上手，编写我们的第一个Project。虽然一个Project的格式并无定法，每个人按照自己的喜好会选择不同的风格，但一个从无受过训练的人，往往写出的Project几乎完全不具有可读性。实际上，学习任何语言，<span></span><em>变量命名规范</em><span></span>、<span></span><em>缩进规范</em><span></span>以及<span></span><em>模块化</em><span></span>、<span></span><em>面向对象</em><span></span>等都被认为是编写一个具有可读性的代码所不得不知的概念。本教程所推荐的代码格式，均具有统一的风格，读者在了解每个Project和其对应的教程时，会慢慢熟悉这种风格的特点。愿读者能从这样的风格中得到启发，得到<span></span><strong>代码可读性</strong><span></span>的神髓。</p>
<h3 id="_8">代码规范<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h3>
<p>建立一个具有较强可读性的Tensorflow工程需要我们活用python的模块化设计。我们通常推荐以下的结构</p>
<div class="codehilite"><pre><span></span>.
├─ data/           <span class="c1"># where we store our data</span>
│  └─ ...
├─ tools.py        <span class="c1"># codes for post-processing and analyzing records.</span>
├─ extension.py    <span class="c1"># codes for extending the tensorflow model.</span>
├─ dparser.py      <span class="c1"># data parser</span>
└─ main.py         <span class="c1"># main module where we define our tensorflow model.</span>
</pre></div>

<p>除了保存数据的文件夹，我们应当有三个子模块。其中</p>
<ul>
<li><code>tool</code>: 用来处理、分析生成的数据，通常与Tensorflow无关；</li>
<li><code>extension</code>: 用来扩展tensorflow，例如在这里自定义网络层和操作符；</li>
<li><code>dparser</code>: 数据处理器，用来读取并预处理送入网络的数据；</li>
<li><code>main</code>: 主模块，只定义跟Tensorflow模型有关的内容，需要引用<code>extension</code>和<code>dparser</code>。</li>
</ul>
<p>视情况可以灵活调整结构，但建议将定义Tensorflow模型的代码单独放在主模块里，和其他外围代码分离。</p>
<p>撰写各个模块时，建议使用类封装各组功能相同的函数。具有良好使用习惯的coder应当注意给各个面向用户的类、函数撰写（哪怕简短的）说明文字，在一些较长的函数、方法的定义中，适当注释各部分的功能，以便读者能正确理解代码意义。</p>
<p>另外，在对象命名上，python有如下必须遵守或不成文的规定，和C/C++用户熟悉的蛇形命名法不同，它大致包括</p>
<ul>
<li>类与函数多用驼峰命名法，变量可以采用驼峰或蛇形命名法。<ul>
<li>驼峰命名法指的是用大小写区分每个单词块，例如<code class="codehilite"><span class="n">alphaBetaFunction</span><span class="p">()</span></code>；</li>
<li>蛇形命名法指的是用下划线区分每个单词块，例如<code class="codehilite"><span class="n">alpha_beta_function</span> <span class="o">=</span> <span class="mi">10</span></code>；</li>
</ul>
</li>
<li>宏变量使用全字大写+蛇形命名法</li>
<li>函数/方法，还有模块均是首字母小写，但类的首字母大写。</li>
<li>用单下划线<code>_</code>表示临时存储器，或省略参数，例如一个函数<code class="codehilite"><span class="n">func</span><span class="p">()</span></code>有两个返回值时，可以用<code class="codehilite"><span class="n">_</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">func</span><span class="p">()</span></code>表示我们只需要第二个返回值；单下划线还可以与星号连用省略多个返回值；</li>
<li>以单下划线开头的方法，表示模块级的私有方法，在模块以外使用<code class="codehilite"><span class="kn">import</span></code>导入类时，不会导入这些方法，例如<code class="codehilite"><span class="k">def</span> <span class="nf">_alphaBeta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span></code>；</li>
<li>以单下划线结尾的对象，用来和python的关键字区分，例如<code class="codehilite"><span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">class_</span><span class="p">)</span></code>;</li>
<li>以双下划线开头的方法，如果不以双下划线结尾，则表示类级的私有方法，只有类内部的方法能调用这些方法，在类外部、包括继承的子类里都原则上不能调用（但其实也有办法调用），例如<code class="codehilite"><span class="k">def</span> <span class="nf">_alphaBeta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span></code>；</li>
<li>以双下划线同时开头和结尾的方法，一般是用来<span></span><strong>重写 (override)</strong><span></span>特殊功能，例如<code class="codehilite"><span class="k">def</span> <span class="fm">__getattribute__</span><span class="p">():</span></code>将重写获得类属性的方法。</li>
</ul>
<h3 id="tensorflow">Tensorflow的数据概念<a class="headerlink" href="#tensorflow" title="Permanent link">&para;</a></h3>
<p>在Tensorflow中，我们把变量都称为“<span></span><strong>张量 (Tensor)</strong><span></span>”。这是因为我们有零维的标量，一维的向量，二维的矩阵，更高维的我们都称为张量。作为一个更大的概念，张量当然也可以用来包括标量、向量和矩阵了。在Tensorflow中，有的张量是<span></span><strong>可以训练 (trainable)</strong><span></span>的，有的则不是。比如一个张量的形状（指各维大小），当然可以是一个<code class="codehilite"><span class="o">&lt;</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="s1">&#39;Shape:0&#39;</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="o">&gt;</span></code>类型的张量，但它不是变量，当然就不可训练。我们也可以人为控制某些张量可以训练或不可以训练，但本节、乃至本章所介绍的凡是我们接触到的张量，都是可以训练的。</p>
<p>特别地，对于神经网络而言，在网络内计算（或者说流动、传播）的一个n维数据，通常按照以下形式组织：</p>
<div class="codehilite"><pre><span></span><span class="n">tensor</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">dimn</span><span class="p">,</span> <span class="n">channel</span><span class="p">]</span>
</pre></div>

<ul>
<li>其中，第一个维度<code>batch</code>一定存在，它表示的是单个batch中的某一个样本。如果一个batch只有一个样本，那么<code>batch</code>只能取0。</li>
<li>从<code>dim1</code>到<code>dimn</code>指的是实际的n维数据的各个维度；</li>
<li><code>channel</code>指的是数据的通道，例如，一个二维RGB图像，每种颜色代表一个通道，因此有三个通道。<code>channel</code>通常用在卷积网络里，我们经常需要在深度卷积网络里不断增大通道数的同时，缩小数据尺寸。</li>
<li>在某些特殊情况下，<code>channel</code>维度可以不存在，例如我们使用的是全连接层而不是卷积网络，<code>tf.keras.layer.Flatten</code>可以用来将一个有通道的张量压缩成一个没有通道的一维向量（但是注意<code>batch</code>维度仍然存在，不会被压缩）。</li>
</ul>
<p>因此，我们知道一个n维的数据，在神经网络中通常被描述为一个n+2维的矩阵，而一个一维向量，在卷积网络里是三维的：</p>
<div class="codehilite"><pre><span></span><span class="n">vector</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">channel</span><span class="p">]</span>
</pre></div>

<p>但是在全连接网络里，是二维的：</p>
<div class="codehilite"><pre><span></span><span class="n">vector</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">channel</span><span class="p">]</span>
</pre></div>

<p>在本节，乃至本章里，我们还不讨论卷积网络，因此我们都是使用二维张量（一维向量组）作为我们的数据。</p>
<h3 id="_9">数据生成<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h3>
<p>在本项目里，我们不需要扩展Tensorflow。但是，我们需要以随机生成数据代替数据集。因此，首先，通过以下代码定义数据生成器</p>
<div class="superfences-tabs">
<input name="__tabs_2" type="radio" id="__tab_2_0" checked="checked" />
<label for="__tab_2_0">dparser.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TestDataSet</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A generator of the data set for testing the linear model.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale_x</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Initialize the data generator.</span>
<span class="sd">        scale_x: the scale of input vector.</span>
<span class="sd">        A, c: the linear transformation.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">scale_x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Configuration</span>
<span class="sd">        train: a flag for controlling the iterator mode.</span>
<span class="sd">        batch: the number of samples in a batch</span>
<span class="sd">        noise: std. of the error added to the y.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span>

    <span class="k">def</span> <span class="nf">next_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Get the next train batch: (x, y)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span><span class="p">])</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span> <span class="o">&gt;</span> <span class="mf">1e-3</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">next_test</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Get the next test batch x.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span><span class="p">])</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">samp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__next__</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">samp</span>

    <span class="k">def</span> <span class="nf">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_train</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_test</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
</div>
<p>该生成器输入一组<span><span class="MathJax_Preview">\mathbf{A},~\mathbf{c}</span><script type="math/tex">\mathbf{A},~\mathbf{c}</script></span>，以及相关配置，之后就可以通过<span></span><strong>迭代器 (iterator)</strong><span></span>或<span></span><strong>方法 (method)</strong><span></span>随机生成数据。这种数据集写法我们在后面还会用到，<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></code>允许我们不是馈入样本（或样本批次），而是馈入一个<span></span><strong>生成器(generator)</strong><span>。因此我们重写了<code class="codehilite"><span class="fm">__iter__</span></code>方法，并使其通过<code>yield</code>返回一个生成器。这样我们定义的数据集类就可以被Keras的训练函数<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></code>使用。接下来，调用如下测试代码：</p>
<div class="superfences-tabs">
<input name="__tabs_3" type="radio" id="__tab_3_0" checked="checked" />
<label for="__tab_3_0">dparser.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">test_dataset</span><span class="p">():</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
        <span class="n">dataSet</span> <span class="o">=</span> <span class="n">TestDataSet</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="n">dIter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dIter</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span>

<span class="n">test_dataset</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_3" type="radio" id="__tab_3_1" />
<label for="__tab_3_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span><span class="p">[</span><span class="mf">0.47</span> <span class="mf">0.57</span> <span class="mf">0.58</span> <span class="mf">0.56</span> <span class="mf">0.5</span>  <span class="mf">0.38</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.6</span>  <span class="mf">0.61</span> <span class="mf">0.47</span> <span class="mf">0.48</span> <span class="mf">0.38</span> <span class="mf">0.52</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.5</span>  <span class="mf">0.61</span> <span class="mf">0.49</span> <span class="mf">0.42</span> <span class="mf">0.45</span> <span class="mf">0.53</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.59</span> <span class="mf">0.52</span> <span class="mf">0.44</span> <span class="mf">0.44</span> <span class="mf">0.49</span> <span class="mf">0.51</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.54</span> <span class="mf">0.59</span> <span class="mf">0.48</span> <span class="mf">0.5</span>  <span class="mf">0.51</span> <span class="mf">0.47</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.49</span> <span class="mf">0.57</span> <span class="mf">0.56</span> <span class="mf">0.49</span> <span class="mf">0.53</span> <span class="mf">0.4</span> <span class="p">]</span>
<span class="p">[</span><span class="mf">0.5</span>  <span class="mf">0.61</span> <span class="mf">0.51</span> <span class="mf">0.54</span> <span class="mf">0.51</span> <span class="mf">0.52</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.5</span>  <span class="mf">0.51</span> <span class="mf">0.61</span> <span class="mf">0.5</span>  <span class="mf">0.44</span> <span class="mf">0.5</span> <span class="p">]</span>
<span class="p">[</span><span class="mf">0.44</span> <span class="mf">0.46</span> <span class="mf">0.53</span> <span class="mf">0.45</span> <span class="mf">0.56</span> <span class="mf">0.52</span><span class="p">]</span>
<span class="p">[</span><span class="mf">0.52</span> <span class="mf">0.46</span> <span class="mf">0.51</span> <span class="mf">0.52</span> <span class="mf">0.49</span> <span class="mf">0.44</span><span class="p">]</span>
</pre></div></div>
</div>
<p>我们随机生成了<span><span class="MathJax_Preview">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</span><script type="math/tex">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</script></span>的数据，每组数据100个，并且测试了10组。输出结果是各组测试中，<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>在对应维度上分类为1的概率估计。结果基本都在0.5左右，说明我们的这种数据生成模式产生的点能均匀分布在各个超平面两侧，适合进行后续测试。</p>
<h3 id="_10">定义线性顺序模型<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<p><span></span><strong>顺序 (sequential)</strong><span></span>模型是一个单输入单输出模型，网络结构较为简单，也不存在跨层短接（残差连接）。在大多数情况下，已经上手的Tensorflow用户不使用这个模型，故而作为我们入门的第一个project，我们姑且用之，但我们将不再使用顺序模型来实现后续的project。一个顺序模型大致可以描述为下图的模式：</p>
<div class="mermaid">graph LR
st(输&lt;br/&gt;入) --&gt; l1[层&lt;br/&gt;1]
l1 --&gt; l2[层&lt;br/&gt;2]
l2 --&gt; l3[层&lt;br/&gt;3]
l3 --&gt; ldots[层&lt;br/&gt;...]
ldots --&gt; ed(输&lt;br/&gt;出)

classDef styStart fill:#FAE6A9,stroke:#BA9132;
class st,ed styStart</div>

<p>由于我们完成的是一个线性分类器，故而我们使用单层的序列模型即可。</p>
<p>接下来，我们来定义一个类，<code class="codehilite"><span class="k">class</span> <span class="nc">LinClsHandle</span><span class="p">:</span></code>。定义一个类的时候，我们通常需要定义的内容包括</p>
<ul>
<li>在初始化方法<code class="codehilite"><span class="fm">__init__</span></code>里定义传入网络的固定参数，例如学习速率，存取路径等；</li>
<li>在方法<code class="codehilite"><span class="n">construct</span></code>里定义网络的构造和使用的优化器；</li>
<li>在方法<code class="codehilite"><span class="n">train</span></code>里定义训练网络的过程，主要需要调用<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></code>。如果我们在数据集的定义非常完善，则这一环节不需要花费太多的功夫；</li>
<li>在方法<code class="codehilite"><span class="n">test</span></code>里定义测试网络的过程，主要需要调用<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span></code>。如果有必要，可以通过<code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">predict</span></code>返回测试结果。</li>
</ul>
<h4 id="_11">初始化方法<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<p>首先，定义初始化方法：</p>
<div class="superfences-tabs">
<input name="__tabs_4" type="radio" id="__tab_4_0" checked="checked" />
<label for="__tab_4_0">lin-cls.py: class LinClsHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">steppe</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Initialization and pass fixed parameters.</span>
<span class="sd">            learning_rate: the learning rate for optimizer.</span>
<span class="sd">            epoch:         training epochs.</span>
<span class="sd">            steppe:        steps per epoch</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steppe</span> <span class="o">=</span> <span class="n">steppe</span>
</pre></div>
</td></tr></table></div>
</div>
<p>由于目前我们的project还非常简单，这里只需要有学习速率(<code>learning_rate</code>)，轮次数(<code>epoch</code>)和每轮迭代次数(<code>steppe</code>)即可。</p>
<h4 id="_12">构造方法<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<p>接下来定义网络构造</p>
<div class="superfences-tabs">
<input name="__tabs_5" type="radio" id="__tab_5_0" checked="checked" />
<label for="__tab_5_0">lin-cls.py: class LinClsHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Construct a linear model and set the optimizer as Adam</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Construction</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">LABEL_SHAPE</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">INPUT_SHAPE</span><span class="p">,),</span> 
                                <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomNormal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">10.0</span><span class="p">),</span> 
                                <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> 
                                <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">)</span>

    <span class="c1"># Set optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span> 
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">()]</span>
    <span class="p">)</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table></div>
</div>
<details class="info" open="open"><summary>须知</summary><p>这里<code>LABEL_SHAPE</code>和<code>INPUT_SHAPE</code>为两个宏变量，分别为输出和输入的向量维度。</p>
</details>
<p>我们使用<code>Dense</code>定义全连接层，它的用法请参照<a href="https://keras-zh.readthedocs.io/layers/core/#dense">这里</a>。由于我们已经知道<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>和<span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>可能的取值范围，这里我们重定义了<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>和<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>的初始化方式。</p>
<details class="info"><summary>信息: Dense API</summary><p><code class="codehilite"><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>指全连接层，其输入一组已知形状的向量，输出一组形状为<code>shape</code>的向量。可用的API如下：</p>
<hr />
<ul>
<li><code>shape</code>: 正整数，输出空间维度。</li>
<li><code>activation</code>: 激活函数。 若不指定，则不使用激活函数 (即，线性激活: <span><span class="MathJax_Preview">a(\mathbf{y}) = \mathbf{y}</span><script type="math/tex">a(\mathbf{y}) = \mathbf{y}</script></span>)。该函数可以定义为任何元素级操作的Tensorflow函数。</li>
<li><code>use_bias</code>: 布尔值，该层是否使用偏置向量。<code class="codehilite"><span class="bp">True</span></code>则网络定义为<span><span class="MathJax_Preview">\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}</span><script type="math/tex">\mathbf{y} = \mathbf{W}\mathbf{x} + \mathbf{b}</script></span>，<code class="codehilite"><span class="bp">False</span></code>则定义为<span><span class="MathJax_Preview">\mathbf{y} = \mathbf{W}\mathbf{x}</span><script type="math/tex">\mathbf{y} = \mathbf{W}\mathbf{x}</script></span>。</li>
<li><code>kernel_initializer</code>: kernel 权值矩阵的初始化器，自定义的初始化器需要使用Keras后端API编写。</li>
<li><code>bias_initializer</code>: 偏置向量的初始化器，同上。</li>
<li><code>kernel_regularizer</code>: 运用到 kernel 权值矩阵的正则化函数，自定义的正则化函数需要使用Keras后端API编写。</li>
<li><code>bias_regularizer</code>: 运用到偏置向的的正则化函数，同上。</li>
<li><code>activity_regularizer</code>: 运用到层的输出的正则化函数，同上。</li>
<li><code>kernel_constraint</code>: 运用到 kernel 权值矩阵的约束函数，只能使用Keras备选的几种方案，不能自定义。</li>
<li><code>bias_constraint</code>: 运用到偏置向量的约束函数，同上。</li>
</ul>
</details>
<details class="info"><summary>信息: model.compile API</summary><p><code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>在这里指的是顺序模型的编译函数，其可用的API如下：</p>
<hr />
<ul>
<li><code>optimizer</code>: 优化器，可以使用Tensorflow内置的优化器。</li>
<li><code>loss</code>: 损失函数，也是目标函数。顺序模型只有一个输出，因此只能传入一个损失函数。可以使用形式为<code class="codehilite"><span class="n">func</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>的Tensorflow函数。</li>
<li><code>metrics</code>: 测度函数，一般是一组函数，如果是一个函数则定义为<code class="codehilite"><span class="p">[</span><span class="n">func</span><span class="p">]</span></code>即可。自定义的测度函数目前还需要使用Keras后端API编写。</li>
<li><code>loss_weights</code>: 损失的权重，顺序模型只有一个损失函数，因此只有一个权重，但要使用一维列表<code class="codehilite"><span class="p">[</span><span class="n">value</span><span class="p">]</span></code>定义。可以使用张量来控制可变权重。</li>
<li><code>sample_weight_mode</code>: 按时间步采样权重，默认不提供。相比上面的损失权重，该选项会随着迭代次数使用不同的权重，因此输入的是二维列表。</li>
<li><code>weighted_metrics</code>: 测度的权重，和损失权重类似，用来加给不同的测度函数。由于我们可以使用不只一个测度函数，这里的权重是个一维列表。</li>
<li><code>target_tensors</code>: 默认情况下，Keras 将为模型的目标创建一个占位符，在训练过程中将使用目标数据。相反，如果你想使用自己的目标张量（反过来说，Keras在训练期间不会载入这些目标张量的外部 Numpy数据），您可以通过<code>target_tensors</code>参数指定它们。对于单输出的顺序模型，它应该是单个张量。</li>
<li><code class="codehilite"><span class="o">**</span><span class="n">kwargs</span></code>: 其他参量，会传递给<code class="codehilite"><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="o">.</span><span class="n">run</span></code>。</li>
</ul>
</details>
<p>另外，注意我们这里构造网络的时候有如下技巧：</p>
<ul>
<li>Tensorflow在导入Keras模式以后，已经不再使用<a href="#mjx-eqn-15"><span><span class="MathJax_Preview">(15)</span><script type="math/tex">(15)</script></span></a>的形式定义<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits">sigmoid交叉熵</a>，而是采取更通用的定义<a href="#mjx-eqn-14"><span><span class="MathJax_Preview">(14)</span><script type="math/tex">(14)</script></span></a>；</li>
<li>我们使用Tensorflow重新封装过的类，<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy">二分类交叉熵 (<code>BinaryCrossentropy</code>)</a>来作为Keras模型的损失函数<code>self.loss</code>，该函数与<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy">多分类交叉熵 (<code>CategoricalCrossentropy</code>)</a>不同，乃是对两组对比张量的每个元素分别计算交叉熵，再求取均值，正符合本应用的需求；</li>
<li>我们通过静态方法，调用Keras的后端API，自己定义了预测准确度的测度函数<code>self.accuracy</code>，同时也使用另一个来自Tensorflow封装好的测度类<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy">二分类准确度 (<code>BinaryAccuracy</code>)</a>，这是为了比照两个准确度的区别，以便我们更好理解该测度类；</li>
<li>我们将网络层的关键字<code>self.dense1</code>保留在了实例中，这是为了确保接下来我们能通过实例抽取该层的参数。</li>
</ul>
<p>需要注意的是，由于<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy">二分类交叉熵</a>，<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy">二分类准确度</a>和<a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy">多分类交叉熵</a>等都是类（从它们的定义都是大写字母开头也可以看出来），因此我们需要在使用的时候后面加上括号以实例化；由于这些类都定义了<code>__call__</code>方法，我们可以像使用函数一样使用它们的实例。</p>
<h4 id="_13">训练和测试方法<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h4>
<p>最后定义的式训练和测试方法。由于我们目前的project还比较简单，关于这两部分都直接调用现有的API即可。使用的API在之前已经说明。<code>model.fit</code>在没有额外设置的情况下，默认会返回一个<a href="https://keras-zh.readthedocs.io/callbacks/#history">History回调器</a>；<code>model.evaluate</code>返回的是测试样本给出的损失函数和准确值测度。<code>model.predict</code>返回的是测试样本给出的网络输出。详情请参照<a href="https://keras-zh.readthedocs.io/models/sequential/">顺序模型API</a>。</p>
<div class="superfences-tabs">
<input name="__tabs_6" type="radio" id="__tab_6_0" checked="checked" />
<label for="__tab_6_0">lin-cls.py: class LinClsHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataSet</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Use a data set to train the network.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">steppe</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Use (data, label) pairs to test the results.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">accu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Evaluated loss     =&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Evaluated accuracy =&#39;</span><span class="p">,</span> <span class="n">accu</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<details class="info"><summary>信息: model.fit API</summary><p><code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>是训练函数，注意这个函数虽然支持输入一组<span><span class="MathJax_Preview">x,~y</span><script type="math/tex">x,~y</script></span>用来代替<code>dataSet</code>，我们还是建议在任何情况下都用dataSet馈送数据，以免内存中数据集占用过多。</p>
<hr />
<ul>
<li><code>dataSet</code>: 数据集，其本身应当是一个<code>tf.data.Dataset</code>类型的类，或者是一个能不断迭代产生新数据的生成器。数据的<code>batch</code>大小由<code>dataSet</code>本身决定。</li>
<li><code>epochs</code>: 整数，终止训练时经历的世代(轮次)数，通常一个epoch表示遍历整个数据集一回。</li>
<li><code>verbose</code>: 0, 1或2。日志显示模式。 0=安静模式, 1=进度条, 2=每轮一行。默认是1。</li>
<li><code>callbacks</code>: 回调器，它是<code>tf.keras.callbacks</code>模块下的类，用来在训练中进行记录保存和数据检查点更新。默认是<code>tf.keras.callbacks.History</code>。</li>
<li><code>validation_split</code>: 在 0 和 1 之间浮动。用作验证集的训练数据的比例。模型将分出一部分不会被训练的验证数据，并将在每一轮结束时评估这些验证数据的误差和任何其他模型指标。验证数据是混洗之前 <code>x</code>和<code>y</code>数据的最后一部分样本中。</li>
<li><code>validation_data</code>: 元组<code>(x_val，y_val)</code>或元组<code>(x_val，y_val，val_sample_weights)</code>，用来评估损失，以及在每轮结束时的任何模型度量指标。模型将不会在这个数据上进行训练。这个参数会覆盖 <code>validation_split</code>。</li>
<li><code>shuffle</code>: 布尔值（是否在每轮迭代之前混洗数据）。当<code>steps_per_epoch</code>非<code class="codehilite"><span class="bp">None</span></code>时，这个参数无效。</li>
<li><code>class_weight</code>: 可选的字典，用来映射类索引（整数）到权重（浮点）值，用于加权损失函数（仅在训练期间）。这可能有助于告诉模型 「更多关注」来自代表性不足的类的样本。</li>
<li><code>sample_weight</code>: 用来给损失函数添加权重，作用类似<code>model.compile</code>的同一参数。</li>
<li><code>initial_epoch</code>: 开始训练的轮次（有助于恢复之前的训练）。</li>
<li><code>steps_per_epoch</code>: 在声明一个轮次完成并开始下一个轮次之前的总步数（样品批次）。使用TensorFlow数据张量等输入张量进行训练时，默认值<code class="codehilite"><span class="bp">None</span></code>等于数据集中样本的数量除以<code>batch</code>的大小，如果无法确定，则为1。</li>
<li><code>validation_steps</code>: 只有在指定了<code>steps_per_epoch</code>时才有用。停止前要验证的总步数（批次样本）。</li>
</ul>
<hr />
<p>该函数会返回<code>callbacks</code>定义的实例。</p>
</details>
<details class="info"><summary>信息 model.evaluate API</summary><p><code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>是测试函数，需要传入<code>label</code>即<code>y</code>来验证性能。</p>
<hr />
<ul>
<li><code>x</code>, <code>y</code>: <code>Numpy</code>数组，分别是输入和输出的真实参照值。</li>
<li><code>batch_size</code>: 计算的<code>batch</code>大小，该函数会将输入的数据组拆分成许多<code>batch</code>分别计算，并组合起来，这个设定值对效果不产生影响，只影响计算过程。</li>
<li><code>verbose</code>: 0, 1。日志显示模式。0=安静模式, 1=进度条。默认是1。</li>
<li><code>sample_weight</code>: 用来给损失函数添加权重，作用类似<code>model.compile</code>的同一参数。</li>
<li><code>steps</code>: 整数或<code class="codehilite"><span class="bp">None</span></code>。 声明评估结束之前的总步数（批次样本）。默认值<code class="codehilite"><span class="bp">None</span></code>。</li>
</ul>
<hr />
<p>该函数会返回损失函数和测度（列表）。</p>
</details>
<details class="info"><summary>信息 model.predict API</summary><p><code class="codehilite"><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>是预测函数，用在只知道输入<code>x</code>的场合。</p>
<hr />
<ul>
<li><code>x</code>: <code>Numpy</code>数组，输入值。</li>
<li><code>batch_size</code>: 计算的<code>batch</code>大小，该函数会将输入的数据组拆分成许多<code>batch</code>分别计算，并组合起来，这个设定值对效果不产生影响，只影响计算过程。</li>
<li><code>verbose</code>: 0, 1。日志显示模式。0=安静模式, 1=进度条。默认是1。</li>
<li><code>steps</code>: 整数或<code class="codehilite"><span class="bp">None</span></code>。 声明评估结束之前的总步数（批次样本）。默认值<code class="codehilite"><span class="bp">None</span></code>。</li>
</ul>
<hr />
<p>该函数返回预测结果。</p>
</details>
<h3 id="_14">调试<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h3>
<p>首先，训练网络。我们随机生成<span><span class="MathJax_Preview">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</span><script type="math/tex">\mathbf{x} \mapsto \mathbf{y}:~\mathbb{R}^{10} \mapsto \mathbb{R}^6</script></span>的仿射变换，并且设置好数据集，给定噪声扰动为<span><span class="MathJax_Preview">\boldsymbol{\varepsilon} \sim \mathcal{N}(0,1)^6</span><script type="math/tex">\boldsymbol{\varepsilon} \sim \mathcal{N}(0,1)^6</script></span>。设定20个epoch，每个epoch迭代500次，每次馈入32个样本构成的batch，然后开始训练：</p>
<div class="superfences-tabs">
<input name="__tabs_7" type="radio" id="__tab_7_0" checked="checked" />
<label for="__tab_7_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Initialization</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="n">INPUT_SHAPE</span><span class="p">,</span> <span class="n">LABEL_SHAPE</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">LABEL_SHAPE</span><span class="p">])</span>
<span class="n">dataSet</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">TestDataSet</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># Construct the model and train it.</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">LinClsHandle</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">steppe</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">h</span><span class="o">.</span><span class="n">construct</span><span class="p">()</span>
<span class="n">record</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_7" type="radio" id="__tab_7_1" />
<label for="__tab_7_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span>Epoch <span class="m">1</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 3ms/step - loss: <span class="m">6</span>.3005 - accuracy: <span class="m">0</span>.5884 - binary_accuracy: <span class="m">0</span>.5884
Epoch <span class="m">2</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">5</span>.4671 - accuracy: <span class="m">0</span>.6407 - binary_accuracy: <span class="m">0</span>.6407
Epoch <span class="m">3</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">4</span>.5711 - accuracy: <span class="m">0</span>.6957 - binary_accuracy: <span class="m">0</span>.6957
Epoch <span class="m">4</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">3</span>.6789 - accuracy: <span class="m">0</span>.7519 - binary_accuracy: <span class="m">0</span>.7519
Epoch <span class="m">5</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">2</span>.7101 - accuracy: <span class="m">0</span>.8127 - binary_accuracy: <span class="m">0</span>.8127
Epoch <span class="m">6</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">2</span>.0059 - accuracy: <span class="m">0</span>.8627 - binary_accuracy: <span class="m">0</span>.8627
Epoch <span class="m">7</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">1</span>.6403 - accuracy: <span class="m">0</span>.8894 - binary_accuracy: <span class="m">0</span>.8894
Epoch <span class="m">8</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">1</span>.3663 - accuracy: <span class="m">0</span>.9066 - binary_accuracy: <span class="m">0</span>.9066
Epoch <span class="m">9</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">1</span>.0466 - accuracy: <span class="m">0</span>.9274 - binary_accuracy: <span class="m">0</span>.9274
Epoch <span class="m">10</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.8377 - accuracy: <span class="m">0</span>.9418 - binary_accuracy: <span class="m">0</span>.9418
Epoch <span class="m">11</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.6465 - accuracy: <span class="m">0</span>.9546 - binary_accuracy: <span class="m">0</span>.9546
Epoch <span class="m">12</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.4492 - accuracy: <span class="m">0</span>.9667 - binary_accuracy: <span class="m">0</span>.9667
Epoch <span class="m">13</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.2795 - accuracy: <span class="m">0</span>.9779 - binary_accuracy: <span class="m">0</span>.9779
Epoch <span class="m">14</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.1624 - accuracy: <span class="m">0</span>.9861 - binary_accuracy: <span class="m">0</span>.9861
Epoch <span class="m">15</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0680 - accuracy: <span class="m">0</span>.9926 - binary_accuracy: <span class="m">0</span>.9926
Epoch <span class="m">16</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0128 - accuracy: <span class="m">0</span>.9971 - binary_accuracy: <span class="m">0</span>.9971
Epoch <span class="m">17</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0055 - accuracy: <span class="m">0</span>.9981 - binary_accuracy: <span class="m">0</span>.9981
Epoch <span class="m">18</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0052 - accuracy: <span class="m">0</span>.9986 - binary_accuracy: <span class="m">0</span>.9986
Epoch <span class="m">19</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0055 - accuracy: <span class="m">0</span>.9981 - binary_accuracy: <span class="m">0</span>.9981
Epoch <span class="m">20</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 1s 2ms/step - loss: <span class="m">0</span>.0049 - accuracy: <span class="m">0</span>.9985 - binary_accuracy: <span class="m">0</span>.9985
</pre></div></div>
</div>
<p>接下来，从训练返回的<code>History</code>类型的回调器中抽取对loss和accuracy的记录。</p>
<div class="superfences-tabs">
<input name="__tabs_8" type="radio" id="__tab_8_0" checked="checked" />
<label for="__tab_8_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Show records</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]),</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cross entropy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;self defined&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">record</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;from tensorflow&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_8" type="radio" id="__tab_8_1" />
<label for="__tab_8_1">Output</label>
<div class="superfences-content"><div class="overflow"><p><img alt="交叉熵损失函数" class="img-fluid" src="../../../assets/images/book-1-x/lincls-loss.svg" tag="2" title="交叉熵损失函数"></p>
<p><img alt="准确度测度" class="img-fluid" src="../../../assets/images/book-1-x/lincls-accu.svg" tag="2" title="准确度测度"></p></div></div>
</div>
<p>结果显示，我们自定义的准确度测度和Tensorflow内置的<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy">二分类准确度</a>完全相同，这说明其本身的定义就是求取所有元素阈值化后，各自分类结果是否正确的平均值。这个实验也让我们对自定义测度函数有了一定的认识。</p>
<p>重新设定数据集的产生方式，变为每个batch含10个样本。使用这组重新随机生成的数据测试网络输出，</p>
<div class="superfences-tabs">
<input name="__tabs_9" type="radio" id="__tab_9_0" checked="checked" />
<label for="__tab_9_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Generate a group of testing samples:</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>

<span class="c1"># Check the testing results</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;True class&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Predicted class&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_9" type="radio" id="__tab_9_1" />
<label for="__tab_9_1">Output</label>
<div class="superfences-content"><div class="overflow"><div class="codehilite"><pre><span></span>Evaluated loss <span class="o">(</span>losses.BinaryCrossentropy<span class="o">)</span>  <span class="o">=</span> <span class="m">0</span>.0023145806044340134
Evaluated accuracy <span class="o">(</span>self defined<span class="o">)</span>           <span class="o">=</span> <span class="m">1</span>.0
Evaluated accuracy <span class="o">(</span>metrics.BinaryAccuracy<span class="o">)</span> <span class="o">=</span> <span class="m">1</span>.0
</pre></div>
<p><img alt="y测量值效果" class="img-fluid" src="../../../assets/images/book-1-x/lincls-res.png" tag="3" title="y测量值效果"></p></div></div>
</div>
<p>注意我们未对测量的结果阈值化，因此显示出来的测量结果和理想值略有差别，但从图可知，阈值化后则测量结果全部准确。</p>
<p>通过抽取<code>h.dense1</code>的参数，我们可以对比<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>和<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>，以及<span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>和<span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>，</p>
<div class="superfences-tabs">
<input name="__tabs_10" type="radio" id="__tab_10_0" checked="checked" />
<label for="__tab_10_0">lin-cls.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Check the regressed values</span>
<span class="n">W</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">dense1</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(),</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(),</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;W&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_10" type="radio" id="__tab_10_1" />
<label for="__tab_10_1">Output</label>
<div class="superfences-content"><div class="overflow"><p><img alt="真实线性变换矩阵A" class="img-fluid" src="../../../assets/images/book-1-x/lincls-A.png" tag="4" title="真实线性变换矩阵A"></p>
<p><img alt="训练得到的线性变换矩阵W" class="img-fluid" src="../../../assets/images/book-1-x/lincls-W.png" tag="4" title="训练得到的线性变换矩阵W"></p>
<p><img alt="对比偏置c, b" class="img-fluid" src="../../../assets/images/book-1-x/lincls-cb.svg" tag="4" title="对比偏置c, b"></p></div></div>
</div>
<p>可以发现，虽然我们训练的分类器十分有效，但其权值和预期的<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>, <span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>并不完全相同。这是由于sigmoid函数激活的特性，使得当预测值偏向最小或最大的情况下，<span><span class="MathJax_Preview">|\sigma(x)| \rightarrow 1</span><script type="math/tex">|\sigma(x)| \rightarrow 1</script></span>，根据<a href="#mjx-eqn-7"><span><span class="MathJax_Preview">(7)</span><script type="math/tex">(7)</script></span></a>，可知其梯度<span><span class="MathJax_Preview">|\sigma(x)(1-\sigma(x))| \rightarrow 0</span><script type="math/tex">|\sigma(x)(1-\sigma(x))| \rightarrow 0</script></span>，因此那些分类结果已经比较确信的样本，其梯度消失，对训练网络的影响忽略不计（这是合理的，因为我们不希望极端样本干扰结果，更希望对分类结果不确切的样本进行训练）。故而，我们虽然可以求解出这个分类问题，但求解到的<span><span class="MathJax_Preview">\mathbf{W}</span><script type="math/tex">\mathbf{W}</script></span>, <span><span class="MathJax_Preview">\mathbf{b}</span><script type="math/tex">\mathbf{b}</script></span>不会回归到<span><span class="MathJax_Preview">\mathbf{A}</span><script type="math/tex">\mathbf{A}</script></span>, <span><span class="MathJax_Preview">\mathbf{c}</span><script type="math/tex">\mathbf{c}</script></span>上。关于回归问题，我们会在下一节进一步讨论。</p>
                
                  
                    <h2 id="__source">来源</h2>
                    
                    
                    
                    
                    <a href="https://github.com/cainmagi/tensorflow-guide/tree//1-1-linear-classification" title="1-1-linear-classification" class="md-source-file">
                      1-1-linear-classification
                    </a>
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://cainmagi.github.io/tensorflow-guide/book-1-x/chapter-1/linear-classification/";
      this.page.identifier =
        "book-1-x/chapter-1/linear-classification/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//tensorflow-guide.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../hello-world/" title="Hello world!" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                Hello world!
              </span>
            </div>
          </a>
        
        
          <a href="../linear-regression/" title="线性回归" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                线性回归
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Yuchen Jin
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../../assets/fonts/font-awesome.css">
    
      <a href="https://cainmagi.github.io/" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="mailto:cainmagi@gmail.com" class="md-footer-social__link fa fa-envelope"></a>
    
      <a href="https://github.com/cainmagi" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/squidfunk" class="md-footer-social__link fa fa-steam"></a>
    
      <a href="https://weibo.com/u/5885093621" class="md-footer-social__link fa fa-weibo"></a>
    
      <a href="https://www.youtube.com/channel/UCzqpNK5qFMy5_cI1i0Z1nQw" class="md-footer-social__link fa fa-youtube-play"></a>
    
      <a href="https://music.163.com/#/user/home?id=276304206" class="md-footer-social__link fa fa-music"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.43ad2ac2.js"></script>
      
        
        
          
          <script src="../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js"></script>
      
        <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
      
        <script src="../../../javascripts/simpleLightbox.min.js"></script>
      
        <script src="../../../javascripts/extensions.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>