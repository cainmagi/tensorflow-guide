



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="本节将讨论如何将一个解析的非线性的回归问题，表述成使用非线性函数激活的线性回归问题。特别地，我们将通过自己定义“激活层”来引入我们定义的解析的非线性函数。">
      
      
        <link rel="canonical" href="https://cainmagi.github.io/tensorflow-guide/book-1-x/chapter-1/nonlinear-regression/">
      
      
        <meta name="author" content="Yuchen Jin (cainmagi)">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="jp">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../../assets/images/icons/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.0.1">
    
    
      
        <title>非线性回归 - Tensorflow手札</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.982221ab.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#ff7043">
      
    
    
      <script src="../../../assets/javascripts/modernizr.1f0bcf2b.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,400,400i,600,700,900|Roboto+Mono">
        <style>body,input{font-family:"Noto Serif SC","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../../stylesheets/main.css">
    
      <link rel="stylesheet" href="../../../stylesheets/extensions.css">
    
      <link rel="stylesheet" href="../../../stylesheets/simpleLightbox.min.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-119875813-2", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="deep-orange" data-md-color-accent="orange">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://cainmagi.github.io/tensorflow-guide/" title="Tensorflow手札" class="md-header-nav__button md-logo">
          
            <img src="../../../assets/images/icons/Tensorflow.svg" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Tensorflow手札
            </span>
            <span class="md-header-nav__topic">
              非线性回归
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/cainmagi/tensorflow-guide" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    cainmagi/tensorflow-guide
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../.." title="TF 1.x" class="md-tabs__link md-tabs__link--active">
          TF 1.x
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://cainmagi.github.io/tensorflow-guide/" title="Tensorflow手札" class="md-nav__button md-logo">
      
        <img src="../../../assets/images/icons/Tensorflow.svg" width="48" height="48">
      
    </a>
    Tensorflow手札
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/cainmagi/tensorflow-guide" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    cainmagi/tensorflow-guide
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1" checked>
    
    <label class="md-nav__link" for="nav-1">
      TF 1.x
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        TF 1.x
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../.." title="扉页" class="md-nav__link">
      扉页
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1-2" type="checkbox" id="nav-1-2" checked>
    
    <label class="md-nav__link" for="nav-1-2">
      从线性问题入门
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-1-2">
        从线性问题入门
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="本章总说" class="md-nav__link">
      本章总说
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../hello-world/" title="Hello world!" class="md-nav__link">
      Hello world!
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../linear-classification/" title="线性分类" class="md-nav__link">
      线性分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../linear-regression/" title="线性回归" class="md-nav__link">
      线性回归
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        非线性回归
      </label>
    
    <a href="./" title="非线性回归" class="md-nav__link md-nav__link--active">
      非线性回归
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="理论" class="md-nav__link">
    理论
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="一般回归问题" class="md-nav__link">
    一般回归问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="非线性解析函数的分解" class="md-nav__link">
    非线性解析函数的分解
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="本节问题" class="md-nav__link">
    本节问题
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="解非线性回归问题" class="md-nav__link">
    解非线性回归问题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" title="自定义网络层" class="md-nav__link">
    自定义网络层
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="学习一个完全规范化的风格" class="md-nav__link">
    学习一个完全规范化的风格
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" title="初始化方法" class="md-nav__link">
    初始化方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="构造方法" class="md-nav__link">
    构造方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" title="回调方法" class="md-nav__link">
    回调方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="输出形状方法" class="md-nav__link">
    输出形状方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="设置提取方法" class="md-nav__link">
    设置提取方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" title="自定义第一层" class="md-nav__link">
    自定义第一层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" title="自定义第二层" class="md-nav__link">
    自定义第二层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" title="检测效果" class="md-nav__link">
    检测效果
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" title="数据生成" class="md-nav__link">
    数据生成
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" title="定义类模型" class="md-nav__link">
    定义类模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" title="调试" class="md-nav__link">
    调试
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
        <li class="md-nav__item">
          <a href="#__source" title="来源" class="md-nav__link md-nav__link--active">
            来源
          </a>
        </li>
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../release-notes/" title="更新记录" class="md-nav__link">
      更新记录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../licenses/" title="协议" class="md-nav__link">
      协议
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" title="理论" class="md-nav__link">
    理论
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" title="一般回归问题" class="md-nav__link">
    一般回归问题
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" title="非线性解析函数的分解" class="md-nav__link">
    非线性解析函数的分解
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" title="本节问题" class="md-nav__link">
    本节问题
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" title="解非线性回归问题" class="md-nav__link">
    解非线性回归问题
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_7" title="自定义网络层" class="md-nav__link">
    自定义网络层
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" title="学习一个完全规范化的风格" class="md-nav__link">
    学习一个完全规范化的风格
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_9" title="初始化方法" class="md-nav__link">
    初始化方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" title="构造方法" class="md-nav__link">
    构造方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" title="回调方法" class="md-nav__link">
    回调方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" title="输出形状方法" class="md-nav__link">
    输出形状方法
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" title="设置提取方法" class="md-nav__link">
    设置提取方法
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" title="自定义第一层" class="md-nav__link">
    自定义第一层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_15" title="自定义第二层" class="md-nav__link">
    自定义第二层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" title="检测效果" class="md-nav__link">
    检测效果
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_17" title="数据生成" class="md-nav__link">
    数据生成
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_18" title="定义类模型" class="md-nav__link">
    定义类模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_19" title="调试" class="md-nav__link">
    调试
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
        <li class="md-nav__item">
          <a href="#__source" title="来源" class="md-nav__link md-nav__link--active">
            来源
          </a>
        </li>
      
      
      
      
        <li class="md-nav__item">
          <a href="#__comments" title="评论" class="md-nav__link md-nav__link--active">
            评论
          </a>
        </li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="_1">非线性回归<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">摘要</p>
<p>本节将讨论如何将一个解析的非线性的回归问题，表述成使用非线性函数激活的线性回归问题。特别地，我们将通过自己定义“激活层”来引入我们定义的解析的非线性函数。</p>
</div>
<h2 id="_2">理论<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="_3">一般回归问题<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>回忆我们的多输出方程<span><span class="MathJax_Preview">\mathbf{y} = \mathcal{F}(x)</span><script type="math/tex">\mathbf{y} = \mathcal{F}(x)</script></span>，其中<span><span class="MathJax_Preview">\mathcal{F}</span><script type="math/tex">\mathcal{F}</script></span>可以是非线性函数，那么我们可以考虑使用一个带可调参数的模型<span><span class="MathJax_Preview">\mathbf{D}_{\boldsymbol{\Theta}}(\mathbf{x})</span><script type="math/tex">\mathbf{D}_{\boldsymbol{\Theta}}(\mathbf{x})</script></span>来模拟它，其中<span><span class="MathJax_Preview">\boldsymbol{\Theta}</span><script type="math/tex">\boldsymbol{\Theta}</script></span>是可调的参数。于是，该问题可以被表述为</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \arg \min_\limits{\boldsymbol{\Theta}} &amp;\sum_{k=1}^N \mathcal{L} \left( \mathbf{y}_k,~ \mathbf{D}_{\boldsymbol{\Theta}}(\mathbf{x}_k) \right),\\
        \mathrm{s.t.}~&amp;\mathbf{y}_k = \mathcal{F}(\mathbf{x}_k).
    \end{aligned}
\end{equation}</div>

<p>其中，<span><span class="MathJax_Preview">(\mathbf{x}_k,~\mathbf{y}_k) \in \mathbb{D}</span><script type="math/tex">(\mathbf{x}_k,~\mathbf{y}_k) \in \mathbb{D}</script></span>来自由非线性函数<span><span class="MathJax_Preview">\mathcal{F}</span><script type="math/tex">\mathcal{F}</script></span>产生的数据集。</p>
<h3 id="_4">非线性解析函数的分解<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>对于一个解析的非线性函数，我们假设任何这样的函数都可以分解成多个复合函数<span><span class="MathJax_Preview">\mathbf{f}_i</span><script type="math/tex">\mathbf{f}_i</script></span>，其中每个复合函数都只包含一个仿射变换<span><span class="MathJax_Preview">\mathbf{h}_j = \mathbf{W}_j \cdot + \mathbf{b}_j</span><script type="math/tex">\mathbf{h}_j = \mathbf{W}_j \cdot + \mathbf{b}_j</script></span>和一个对在各元素操作的非线性激活函数<span><span class="MathJax_Preview">\Lambda_j</span><script type="math/tex">\Lambda_j</script></span>。因此，复合函数可以写作<span><span class="MathJax_Preview">\mathbf{f}_i = \Lambda_j \circ \mathbf{h}_j</span><script type="math/tex">\mathbf{f}_i = \Lambda_j \circ \mathbf{h}_j</script></span>。于是，整个非线性的函数可以表述为：</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \mathcal{F} = \Lambda_M \circ \mathbf{h}_M \circ \Lambda_{M-1} \circ \mathbf{h}_{M-1} \circ \cdots \Lambda_1 \circ \mathbf{h}_1.
    \end{aligned}
\end{equation}</div>

<p>例如，对函数</p>
<div class="overflow">\begin{align}
    \mathcal{F}(\mathbf{x}) = \exp( \mathbf{A} \log ( | \mathbf{B} \mathbf{x} + \mathbf{c} | )  ).
\end{align}</div>

<p>可以分解为：</p>
<ol>
<li><span><span class="MathJax_Preview">\mathbf{h}_1 (\mathbf{x}) = \mathbf{B} \mathbf{x} + \mathbf{c}</span><script type="math/tex">\mathbf{h}_1 (\mathbf{x}) = \mathbf{B} \mathbf{x} + \mathbf{c}</script></span>；</li>
<li><span><span class="MathJax_Preview">\Lambda_1 (\mathbf{h}_1) = \log ( | \mathbf{h}_1 | )</span><script type="math/tex">\Lambda_1 (\mathbf{h}_1) = \log ( | \mathbf{h}_1 | )</script></span>；</li>
<li><span><span class="MathJax_Preview">\mathbf{h}_2 (\Lambda_1) = \mathbf{A} \Lambda_1</span><script type="math/tex">\mathbf{h}_2 (\Lambda_1) = \mathbf{A} \Lambda_1</script></span>；</li>
<li><span><span class="MathJax_Preview">\Lambda_2 (\mathbf{h}_2) = \exp ( \mathbf{h}_2 )</span><script type="math/tex">\Lambda_2 (\mathbf{h}_2) = \exp ( \mathbf{h}_2 )</script></span>。</li>
</ol>
<p>实际上，当然还存在更复杂的情况，例如，一个非线性函数<span><span class="MathJax_Preview">\mathbf{f}_j</span><script type="math/tex">\mathbf{f}_j</script></span>是两个非线性函数的和、积、商，或是某函数导数的范数等……但原则上，这些函数都可以写作上述（多个）可分解复合函数的（联合）变换。本质上，函数中的任何参数，都可以看作是在参与一个仿射变换。因此，任何函数只要能写出解析式，理论上就能分解为（多个）上述的可分解函数的形式。</p>
<p>相信有一点功底的读者都可以看出，<a href="#mjx-eqn-2"><span><span class="MathJax_Preview">(2)</span><script type="math/tex">(2)</script></span></a>其实就是一个神经网络的表达式。换言之，只要知道一个函数的解析式，我们就可以用一个或多个神经网络来为其建模。虽然我们可能不知道这个函数里具体的参数值，但通过对网络训练，我们可以让网络的参数回归到函数的参数上。</p>
<h3 id="_5">本节问题<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>考虑一组三角函数的线性组合，使得列向量<span><span class="MathJax_Preview">\mathbf{x} \in \mathbb{R}^T</span><script type="math/tex">\mathbf{x} \in \mathbb{R}^T</script></span>映射到列向量<span><span class="MathJax_Preview">\mathbf{y} \in \mathbb{R}^T</span><script type="math/tex">\mathbf{y} \in \mathbb{R}^T</script></span>，其中<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>，<span><span class="MathJax_Preview">\mathbf{y}</span><script type="math/tex">\mathbf{y}</script></span>均为时间域上的变量，则：</p>
<div class="overflow">\begin{align}
    \mathbf{y} = \sum_{i=1}^N a_i \cos ( \omega_i \mathbf{x} + \varphi_i ).
\end{align}</div>

<p>如果我们将其写成矩阵的形式，应当有</p>
<div class="overflow">\begin{align}
    \mathbf{y} = \cos ( \mathbf{x} \boldsymbol{\omega}^T + \mathbf{1} \boldsymbol{\varphi}^T ) \mathbf{a}.
\end{align}</div>

<p>设若我们有大量的样本<span><span class="MathJax_Preview">(\mathbf{x}_k,~\mathbf{y}_k)</span><script type="math/tex">(\mathbf{x}_k,~\mathbf{y}_k)</script></span>，但我们不知道参数<span><span class="MathJax_Preview">\boldsymbol{\omega},~\boldsymbol{\varphi},~\mathbf{a}</span><script type="math/tex">\boldsymbol{\omega},~\boldsymbol{\varphi},~\mathbf{a}</script></span>。若我们想在频率域上拟合出该模型的参数，则根据<a href="#mjx-eqn-1"><span><span class="MathJax_Preview">(1)</span><script type="math/tex">(1)</script></span></a>，该问题可以写作：</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \arg \min_\limits{\boldsymbol{\omega},~\boldsymbol{\varphi},~\mathbf{a}} &amp;\sum_{k=1}^K \lVert \mathrm{Re}\{\mathbf{Y}_k - \hat{\mathbf{Y}}_k \} \rVert_2^2 + \lVert \mathrm{Im}\{\mathbf{Y}_k - \hat{\mathbf{Y}}_k \} \rVert^2_2,\\
        \mathrm{s.t.}~&amp;\mathbf{Y}_k = \mathrm{FFT}(\mathbf{y}_k), \\
        &amp;\hat{\mathbf{Y}}_k = \mathrm{FFT}(\cos ( \mathbf{x}_k \boldsymbol{\omega}^T + \mathbf{1} \boldsymbol{\varphi}^T ) \mathbf{a}).
    \end{aligned}
\end{equation}</div>

<p>其中，FFT指<a href="https://en.wikipedia.org/wiki/Fourier_transform">快速傅里叶变换</a>，虽然FFT是一个线性变换，但显然，该问题是一个非线性问题，这是由于预测值的表达式<span><span class="MathJax_Preview">\hat{\mathbf{y}}</span><script type="math/tex">\hat{\mathbf{y}}</script></span>的表达式<a href="#mjx-eqn-5"><span><span class="MathJax_Preview">(5)</span><script type="math/tex">(5)</script></span></a>是非线性的。</p>
<p>由于表达式<a href="#mjx-eqn-5"><span><span class="MathJax_Preview">(5)</span><script type="math/tex">(5)</script></span></a>是一个显式函数，相比上一节求取低秩近似的仿射变换，我们可以知道，即使该问题即使存在多个不同的<span><span class="MathJax_Preview">\mathbf{x}_k</span><script type="math/tex">\mathbf{x}_k</script></span>对应同一个<span><span class="MathJax_Preview">\mathbf{y}_k</span><script type="math/tex">\mathbf{y}_k</script></span>，也不影响我们对问题的求解（即训练得到的参数能和真实参数产生相同的输出）。然而，从这里的参数的定义可以看出，我们在这个问题中使用的参数是非常低秩的（所有的参数秩均为1），这将导致这个问题的解具有高度的不确定性，许多不同的参数组<span><span class="MathJax_Preview">\boldsymbol{\omega},~\boldsymbol{\varphi},~\mathbf{a}</span><script type="math/tex">\boldsymbol{\omega},~\boldsymbol{\varphi},~\mathbf{a}</script></span>均能达到相同的效果。例如，我们已知三个参数向量是长度相同的，若我们选取三个向量各自的第<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>个元素，和其对应的第<span><span class="MathJax_Preview">j</span><script type="math/tex">j</script></span>个元素相互交换（例如<span><span class="MathJax_Preview">\omega_i \leftrightarrow \omega_j</span><script type="math/tex">\omega_i \leftrightarrow \omega_j</script></span>），则根据<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>，这两个不同的解均能产生相同的效果。另一个例子是，由于余弦函数具有周期性，对<span><span class="MathJax_Preview">\boldsymbol{\varphi}</span><script type="math/tex">\boldsymbol{\varphi}</script></span>的任意元素<span><span class="MathJax_Preview">\varphi_i</span><script type="math/tex">\varphi_i</script></span>，即使令<span><span class="MathJax_Preview">\varphi_i = \varphi_i + 2 \pi</span><script type="math/tex">\varphi_i = \varphi_i + 2 \pi</script></span>，仍不影响拟合的效果。因此，通过<a href="#mjx-eqn-6"><span><span class="MathJax_Preview">(6)</span><script type="math/tex">(6)</script></span></a>求解的向量<span><span class="MathJax_Preview">\boldsymbol{\varphi}</span><script type="math/tex">\boldsymbol{\varphi}</script></span>也具有不确定性。</p>
<p>根据我们前面提到的对非线性解析函数的分解方法，该问题的模型可以分解为：</p>
<ol>
<li><span><span class="MathJax_Preview">\mathbf{h}_1 (\mathbf{x})= \mathbf{x} \boldsymbol{\omega}^T + \mathbf{1} \boldsymbol{\varphi}^T</span><script type="math/tex">\mathbf{h}_1 (\mathbf{x})= \mathbf{x} \boldsymbol{\omega}^T + \mathbf{1} \boldsymbol{\varphi}^T</script></span>；</li>
<li><span><span class="MathJax_Preview">\Lambda_1 (\mathbf{h}_1) = \cos ( \mathbf{h}_1 )</span><script type="math/tex">\Lambda_1 (\mathbf{h}_1) = \cos ( \mathbf{h}_1 )</script></span>；</li>
<li><span><span class="MathJax_Preview">\mathbf{h}_2 (\Lambda_1) = \Lambda_1 \mathbf{a}</span><script type="math/tex">\mathbf{h}_2 (\Lambda_1) = \Lambda_1 \mathbf{a}</script></span>；</li>
<li><span><span class="MathJax_Preview">\hat{\mathbf{Y}} = \Lambda_2 (\mathbf{h}_2) = \mathrm{FFT} ( \mathbf{h}_2 )</span><script type="math/tex">\hat{\mathbf{Y}} = \Lambda_2 (\mathbf{h}_2) = \mathrm{FFT} ( \mathbf{h}_2 )</script></span>。</li>
</ol>
<h2 id="_6">解非线性回归问题<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<p>我们已经知道，该问题可以建立成一个两层的模型，两层的变换函数和激活函数分别为<span><span class="MathJax_Preview">(\mathbf{h}_1,~\Lambda_1)</span><script type="math/tex">(\mathbf{h}_1,~\Lambda_1)</script></span>, <span><span class="MathJax_Preview">(\mathbf{h}_2,~\Lambda_2)</span><script type="math/tex">(\mathbf{h}_2,~\Lambda_2)</script></span>。然而，实现该模型仍然存在技术问题。即，神经网络中，并未定义<span><span class="MathJax_Preview">\mathbf{h}_1,~\mathbf{h}_2,~\Lambda_2</span><script type="math/tex">\mathbf{h}_1,~\mathbf{h}_2,~\Lambda_2</script></span>的层API，因此，我们必须自己来实现这些功能。</p>
<p>这一节讨论的内容更偏向于技术实现，而且对新入门的读者而言具有一定的难度。但本节讨论的技术，即自定义网络层，实在是非常广泛地应用在Keras API的用户中。例如，著名的Residual network和Inception network，在Tensorflow-Keras API中均未提供现成的API，需要读者自行设法构造。</p>
<p>熟悉旧版Tensorflow的用户，可能会发现，在实现自定义API的过程上，旧版API使用起来更容易上手；然而，Keras式的API也有其好处，那就是强制用户必须按照规范、统一的标准处理API的定义和接口，使得用户更容易建立规范的编写习惯。</p>
<h3 id="_7">自定义网络层<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<p>自定义Keras层的方法可以参照：</p>
<p><a href="https://keras-zh.readthedocs.io/layers/writing-your-own-keras-layers/">编写你自己的Keras层 - Keras中文文档</a></p>
<p>编写好的层是一个类API，可以同时被顺序模型或类模型调用。</p>
<h4 id="_8">学习一个完全规范化的风格<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<p>让我们观察Tensorflow-keras模型对最简单的层，全连接层<code>Dense</code>的定义（我们之前也分别在顺序模型和类模型中使用过该API）。下面的内容摘自<a href="https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/layers/core.py#L849">Tensorflow源码</a>：</p>
<div class="superfences-tabs">
<input name="__tabs_1" type="radio" id="__tab_1_0" checked="checked" />
<label for="__tab_1_0">import</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="kn">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">common_shapes</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">tensor_shape</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">activations</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">constraints</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">initializers</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="kn">import</span> <span class="n">regularizers</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine.base_layer</span> <span class="kn">import</span> <span class="n">Layer</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine.input_spec</span> <span class="kn">import</span> <span class="n">InputSpec</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils</span> <span class="kn">import</span> <span class="n">conv_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils</span> <span class="kn">import</span> <span class="n">generic_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils</span> <span class="kn">import</span> <span class="n">tf_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">gen_math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">nn_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">standard_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="kn">import</span> <span class="n">tf_export</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_1" />
<label for="__tab_1_1">class Dense</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;keras.layers.Dense&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
               <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
               <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_2" />
<label for="__tab_1_2">doc string</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
   <span class="sd">&quot;&quot;&quot;Just your regular densely-connected NN layer.</span>
<span class="sd">  `Dense` implements the operation:</span>
<span class="sd">  `output = activation(dot(input, kernel) + bias)`</span>
<span class="sd">  where `activation` is the element-wise activation function</span>
<span class="sd">  passed as the `activation` argument, `kernel` is a weights matrix</span>
<span class="sd">  created by the layer, and `bias` is a bias vector created by the layer</span>
<span class="sd">  (only applicable if `use_bias` is `True`).</span>
<span class="sd">  Note: if the input to the layer has a rank greater than 2, then</span>
<span class="sd">  it is flattened prior to the initial dot product with `kernel`.</span>
<span class="sd">  Example:</span>
<span class="sd">      # as first layer in a sequential model:</span>
<span class="sd">      model = Sequential()</span>
<span class="sd">      model.add(Dense(32, input_shape=(16,)))</span>
<span class="sd">      # now the model will take as input arrays of shape (*, 16)</span>
<span class="sd">      # and output arrays of shape (*, 32)</span>
<span class="sd">      # after the first layer, you don&#39;t need to specify</span>
<span class="sd">      # the size of the input anymore:</span>
<span class="sd">      model.add(Dense(32))</span>
<span class="sd">  Arguments:</span>
<span class="sd">      units: Positive integer, dimensionality of the output space.</span>
<span class="sd">      activation: Activation function to use.</span>
<span class="sd">          If you don&#39;t specify anything, no activation is applied</span>
<span class="sd">          (ie. &quot;linear&quot; activation: `a(x) = x`).</span>
<span class="sd">      use_bias: Boolean, whether the layer uses a bias vector.</span>
<span class="sd">      kernel_initializer: Initializer for the `kernel` weights matrix.</span>
<span class="sd">      bias_initializer: Initializer for the bias vector.</span>
<span class="sd">      kernel_regularizer: Regularizer function applied to</span>
<span class="sd">          the `kernel` weights matrix.</span>
<span class="sd">      bias_regularizer: Regularizer function applied to the bias vector.</span>
<span class="sd">      activity_regularizer: Regularizer function applied to</span>
<span class="sd">          the output of the layer (its &quot;activation&quot;)..</span>
<span class="sd">      kernel_constraint: Constraint function applied to</span>
<span class="sd">          the `kernel` weights matrix.</span>
<span class="sd">      bias_constraint: Constraint function applied to the bias vector.</span>
<span class="sd">  Input shape:</span>
<span class="sd">      nD tensor with shape: `(batch_size, ..., input_dim)`.</span>
<span class="sd">      The most common situation would be</span>
<span class="sd">      a 2D input with shape `(batch_size, input_dim)`.</span>
<span class="sd">  Output shape:</span>
<span class="sd">      nD tensor with shape: `(batch_size, ..., units)`.</span>
<span class="sd">      For instance, for a 2D input with shape `(batch_size, input_dim)`,</span>
<span class="sd">      the output would have shape `(batch_size, units)`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_3" />
<label for="__tab_1_3">Dense.__init__</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">units</span><span class="p">,</span>
               <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
               <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
               <span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
               <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">bias_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;input_shape&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="s1">&#39;input_dim&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;input_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;input_dim&#39;</span><span class="p">),)</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">activity_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activity_regularizer</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_initializer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bias_initializer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_regularizer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bias_regularizer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_constraint</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bias_constraint</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span><span class="n">min_ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_4" />
<label for="__tab_1_4">Dense.build</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The last dimension of the inputs to `Dense` &#39;</span>
                       <span class="s1">&#39;should be defined. Found `None`.&#39;</span><span class="p">)</span>
    <span class="n">last_dim</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span><span class="n">min_ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">axes</span><span class="o">=</span><span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">last_dim</span><span class="p">})</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
        <span class="s1">&#39;kernel&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">last_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">],</span>
        <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">,</span>
        <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">,</span>
        <span class="n">constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
          <span class="s1">&#39;bias&#39;</span><span class="p">,</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,],</span>
          <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span><span class="p">,</span>
          <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span><span class="p">,</span>
          <span class="n">constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_5" />
<label for="__tab_1_5">Dense.call</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">common_shapes</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
      <span class="c1"># Broadcasting is required for the inputs.</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">standard_ops</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="p">[[</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
      <span class="c1"># Reshape the output back to the original ndim of the input.</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
        <span class="n">output_shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">]</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">gen_math_ops</span><span class="o">.</span><span class="n">mat_mul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>
    <span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_6" />
<label for="__tab_1_6">Dense.compute_output_shape</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;The innermost dimension of input_shape must be defined, but saw: </span><span class="si">%s</span><span class="s1">&#39;</span>
          <span class="o">%</span> <span class="n">input_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_1" type="radio" id="__tab_1_7" />
<label for="__tab_1_7">Dense.get_config</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;units&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
        <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">activations</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">),</span>
        <span class="s1">&#39;use_bias&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="s1">&#39;kernel_initializer&#39;</span><span class="p">:</span> <span class="n">initializers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">),</span>
        <span class="s1">&#39;bias_initializer&#39;</span><span class="p">:</span> <span class="n">initializers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span><span class="p">),</span>
        <span class="s1">&#39;kernel_regularizer&#39;</span><span class="p">:</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;bias_regularizer&#39;</span><span class="p">:</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;activity_regularizer&#39;</span><span class="p">:</span>
            <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activity_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;kernel_constraint&#39;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">),</span>
        <span class="s1">&#39;bias_constraint&#39;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">base_config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_config</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>
</td></tr></table></div>
</div>
<p>为了便于读者阅读，我们将它按照重定义的方法分成了几片不同的代码。下面我们来分别观察不同代码里实现的内容。</p>
<h5 id="_9">初始化方法<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h5>
<p>首先，在<code>__init__</code>方法中，定义了用来初始化该层的所有可选参数。从这一段代码，可以观察到以下结论：</p>
<ol>
<li><code>units</code>是<code>Dense</code>的输出维度，是唯一一个必选参量，并用<code>int()</code>强制转换的方式确保输入的是整数。</li>
<li>除了布尔类型的输入，其他所有的输入都使用<code>tensorflow.python.keras</code>下的对应方法保护起来。例如，<code>kernel_regularizer</code>的实现通过<code>keras.regularizers</code>方法初始化。这是为了确保用户使用该接口时，既可以使用字符串指定正则化器，也可以通过一个现成的正则化器实例来指定。</li>
<li><code>supports_masking</code>和<code>input_spec</code>这两个量由类本身决定，不受用户初始化参数的影响。<ol>
<li><code>input_spec</code>用来限定输入网络的张量必须具有哪些属性，参见官方文档对<a href="https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/layers/InputSpec?hl=en"><code>tf.keras.layers.InputSpec</code></a>的说明。</li>
<li><code>supports_masking</code>用来表示该输入是否支持<code>Masking</code>层，参见<a href="https://keras-zh.readthedocs.io/layers/core/#masking">Masking - Keras中文文档</a>对该层的介绍。它主要用来取消时序模型（一般是RNN/LSTM）中缺失的时间点数据对网络结果的影响。一般来说，一个与时序无关的（或者称为时不变(timeless)的）模型，直接设该值为True即可。</li>
</ol>
</li>
<li>特别地，<code>activity_regularizer</code>通过覆盖输入参量的默认值来实现。这是因为在<code>Dense</code>的父类<code>Layer</code>中，已经定义过<code>activity_regularizer</code>。其他的参量不能通过这种方式实现，是因为它们都跟新加入的参数有关。</li>
</ol>
<h5 id="_10">构造方法<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h5>
<p>接下来，让我们观察<code>build</code>方法。在该方法中，我们实现了网络中各参数的构造过程。</p>
<ol>
<li>首先，通过<code>input_shape</code>来得到输入张量的形状。在本例中，特别检查了<code>input_shape</code>的规范性，确保输入数据的最后一个维度值为已知。因为，<code>Dense</code>的API允许用户只通过输入来自上一层的张量，来推断全连接层的输入维度。特别地，如果我们的层有多个输入，<code>input_shape</code>会是一个<code>list</code>类型。</li>
<li>接下来，通过<code>self.add_weight</code>或<code>self.add_variable</code>来添加参数。该方法的用法参见官方文档中的<a href="https://www.tensorflow.org/versions/r1.13/api_docs/python/tf/keras/layers/Layer#add_weight"><code>Layers.add_weight</code></a>。它接受包括初始化器<code>initializer</code>，正则化器<code>regularizer</code>等一系列参数，这些参数都要求必须是具有回调属性的实例。这一条件我们已经在<code>__init__</code>方法中满足了。</li>
<li>最后，设定<code>self.built</code>为<code class="codehilite"><span class="bp">True</span></code>。事实上，Keras推荐我们使用类似<code class="codehilite"><span class="nb">super</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span></code>的方式来完成这一设置，这种做法和显式地设定<code>self.built</code>等价。</li>
</ol>
<h5 id="_11">回调方法<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h5>
<p>接下来观察<code>call</code>方法。该方法接受的是该层实际输入的张量，同时也输出一个张量，该输出张量即使该层的输出结果。可以说，在该方法中，我们才正式开始实现层的实际功能。</p>
<p>在该范例中，该方法的实现是通过Tensorflow最底层的标准API。这些API对用户来说是封装起来的，一般情况下用户不需要使用它们。实际上，该方法实现的就是<span><span class="MathJax_Preview">\mathbf{y} = \mathbf{W} \mathbf{x} + \mathbf{b}</span><script type="math/tex">\mathbf{y} = \mathbf{W} \mathbf{x} + \mathbf{b}</script></span>的过程。这种代码风格显得颇为繁琐，但是它提供了精密的参数检查和高效的API操作。我们不会讨论这段代码的具体实现细节，因为它既然是被封装的API，我们一般来说就不需要调用它们实现功能（除非我们需要修改使用同样被封装的底层API所编写的模块）。等价地，我们分别介绍Keras API和Tensorflow API如何做到相同的效果。</p>
<p>首先是Keras API版本的等效代码，它修改自<a href="https://keras-zh.readthedocs.io/layers/writing-your-own-keras-layers/">Keras中文文档</a>：</p>
<div class="superfences-tabs">
<input name="__tabs_2" type="radio" id="__tab_2_0" checked="checked" />
<label for="__tab_2_0">Dense.call</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</td></tr></table></div>
</div>
<p>接下来是Tensorflow API版本的等效代码，</p>
<div class="superfences-tabs">
<input name="__tabs_3" type="radio" id="__tab_3_0" checked="checked" />
<label for="__tab_3_0">Dense.call</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="p">[[</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</td></tr></table></div>
</div>
<p>与Keras API的实现相比，Tensorflow API主要区别是使用<code>tf.tensordot</code>时需要指定执行矩阵计算的两轴。实际上，使用Tensorflow API对已经较为熟悉Tensorflow旧版API的用户是十分亲切的，它使我们找回了当初自己编写中层API的感觉。</p>
<h5 id="_12">输出形状方法<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h5>
<p>接下来观察<code>compute_output_shape</code>方法。我们知道Tensorflow-Keras支持对每一层的输入输出作形状推断，而形状推断的具体实现就在这一步。</p>
<details class="question" open="open"><summary>问题</summary><p><em>为什么我们需要定义这个方法？难道我们不可以直接通过对输出张量计算<code>K.shape(output)</code>或<code>tf.shape(output)</code>来确定输出形状吗？</em></p>
<p>这是由于，对Tensorflow-Keras而言，推断网络各层的形状和推断网络各层的张量是两码事。定义该方法能够确保我们在不调用任何一个<code>call</code>方法的前提下，推断出整个网络各层的输入、输出形状。</p>
</details>
<p>这里实现这一方法的过程仍然是调用Tensorflow的最底层API。事实上，Keras API对这一方法的输出并没有严格的要求，它可以是一个<code>tf.Shape</code>，可以是一个<code>list</code>/<code>tuple</code>，还可以是将两者元素混合在一起的<code>list</code>。我们不考虑对输入形状进行这些检查，那么，一个简单的，Keras风格的改写是</p>
<div class="superfences-tabs">
<input name="__tabs_4" type="radio" id="__tab_4_0" checked="checked" />
<label for="__tab_4_0">Dense.compute_output_shape</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<p>或者我们可以更规范一点，使用Tensorflow API来确保该方法的输入、输出和具体操作都是对<code>tf.Shape</code>进行的</p>
<div class="superfences-tabs">
<input name="__tabs_5" type="radio" id="__tab_5_0" checked="checked" />
<label for="__tab_5_0">Dense.compute_output_shape</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
</div>
<h5 id="_13">设置提取方法<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h5>
<p>最后，在<code>get_config</code>中，我们将我们自定义的所有参数实例，通过<code>serialize</code>方法加入到该层的参数设置字典中。实现这一步是颇为重要的（但是在<a href="https://keras-zh.readthedocs.io/layers/writing-your-own-keras-layers/">Keras中文文档</a>中并未提及），它允许我们将我们自己定义的网络层编译成一个包含设置信息的字典，并允许我们通过该字典重构出具有相同参数设置的层来，参见：</p>
<p><a href="https://keras-zh.readthedocs.io/layers/about-keras-layers/">关于Keras网络层 - Keras中文文档</a></p>
<p>例如，对一个<code>Dense</code>层，通过该方法重构的步骤是</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="n">reconstructed_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>综上，我们可以从官方代码如何定义<code>Dense</code>层学习到我们自己应该如何定义类似的层。事实上，我们建议读者在自定义任何层之前，先选择一个与我们要自定义的层形式相似的层，阅览官方代码，了解定义一个这样的层大致的步骤，然后再开始实际行动。</p>
<h4 id="_14">自定义第一层<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h4>
<p>接下来，我们考虑来自己构造一个层API。该层的表达式为：</p>
<div class="overflow">\begin{align}
    \mathbf{y} = \eta ( \mathbf{x} \boldsymbol{\omega}^T + \mathbf{1} \boldsymbol{\varphi}^T ),
\end{align}</div>

<p>这里<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>为输入的列向量（但是注意在代码中它是行向量），<span><span class="MathJax_Preview">\mathbf{1}</span><script type="math/tex">\mathbf{1}</script></span>是一个与<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>形状相同的，值全为1的向量；<span><span class="MathJax_Preview">\boldsymbol{\omega},~\boldsymbol{\varphi}</span><script type="math/tex">\boldsymbol{\omega},~\boldsymbol{\varphi}</script></span>为可训练的参数，而<span><span class="MathJax_Preview">\eta(\cdot)</span><script type="math/tex">\eta(\cdot)</script></span>是一个应用在元素级的激活函数。我们考虑实现以下功能：</p>
<ul>
<li>该层输入一个形状为<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">]</span></code>的向量组，输出一个形状为<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span></code>的矩阵组，其中<code>M</code>是参数<span><span class="MathJax_Preview">\boldsymbol{\omega}</span><script type="math/tex">\boldsymbol{\omega}</script></span>的长度。因此，该层不需要获取输入向量的形状，但需要定义输出矩阵的列数<code>M</code>。换言之，该层的作用是将向量升维成低秩矩阵；</li>
<li>参数<span><span class="MathJax_Preview">\boldsymbol{\omega},~\boldsymbol{\varphi}</span><script type="math/tex">\boldsymbol{\omega},~\boldsymbol{\varphi}</script></span>都可以指定初始化器、正则化器和限制条件，就像<code>Dense</code>层一样；</li>
<li>可以选择是否使用<span><span class="MathJax_Preview">\boldsymbol{\varphi}</span><script type="math/tex">\boldsymbol{\varphi}</script></span>，就像在<code>Dense</code>层我们可以选择是否使用<code>biase</code>一样；</li>
<li>激活函数<span><span class="MathJax_Preview">\eta(\cdot)</span><script type="math/tex">\eta(\cdot)</script></span>可以是一个任意的激活函数，并且允许我们为它添加正则化器。</li>
</ul>
<p>综上，我们定义该层为<code class="codehilite"><span class="k">class</span> <span class="nc">UpDimAffine</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span></code></p>
<div class="superfences-tabs">
<input name="__tabs_6" type="radio" id="__tab_6_0" checked="checked" />
<label for="__tab_6_0">UpDimAffine.__init__</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
             <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
             <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
             <span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;input_shape&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="s1">&#39;input_dim&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;input_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;input_dim&#39;</span><span class="p">),)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">UpDimAffine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">activity_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activity_regularizer</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_initializer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bias_initializer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_regularizer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bias_regularizer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_constraint</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">bias_constraint</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span><span class="n">min_ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_6" type="radio" id="__tab_6_1" />
<label for="__tab_6_1">UpDimAffine.build</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
                    <span class="s1">&#39;kernel&#39;</span><span class="p">,</span>
                    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">],</span>
                    <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">,</span>
                    <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">,</span>
                    <span class="n">constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
                    <span class="s1">&#39;bias&#39;</span><span class="p">,</span>
                    <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">],</span>
                    <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span><span class="p">,</span>
                    <span class="n">regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span><span class="p">,</span>
                    <span class="n">constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">UpDimAffine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_6" type="radio" id="__tab_6_2" />
<label for="__tab_6_2">UpDimAffine.call</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">ndims</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="p">[[</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">:</span>
        <span class="n">varbias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="p">[[</span><span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">varbias</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_6" type="radio" id="__tab_6_3" />
<label for="__tab_6_3">UpDimAffine.compute_output_shape</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_6" type="radio" id="__tab_6_4" />
<label for="__tab_6_4">UpDimAffine.get_config</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;units&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
        <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="n">activations</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">),</span>
        <span class="s1">&#39;use_bias&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="s1">&#39;kernel_initializer&#39;</span><span class="p">:</span> <span class="n">initializers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">),</span>
        <span class="s1">&#39;bias_initializer&#39;</span><span class="p">:</span> <span class="n">initializers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span><span class="p">),</span>
        <span class="s1">&#39;kernel_regularizer&#39;</span><span class="p">:</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;bias_regularizer&#39;</span><span class="p">:</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;activity_regularizer&#39;</span><span class="p">:</span>
            <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activity_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;kernel_constraint&#39;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">),</span>
        <span class="s1">&#39;bias_constraint&#39;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">base_config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">UpDimAffine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_config</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>
</td></tr></table></div>
</div>
<p>这组定义完全启发自<code>Dense</code>的定义，因此改动其实不多，与<code>Dense</code>相比，主要的区别是<code>call</code>方法的实现。特别地，与<code>Dense</code>相同的是，我们使用<code>tf.tensordot</code>来指定对两个高维度的张量，取前一个张量的最后一维和第二个张量的第一维来进行矩阵乘法。</p>
<h4 id="_15">自定义第二层<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h4>
<p>第二层的表达式为：</p>
<div class="overflow">\begin{equation}
    \begin{aligned}
        \mathbf{y}_1 = \mathrm{Re}\{ \mathrm{FFT}( \mathbf{x} \mathbf{a} ) \}, \\
        \mathbf{y}_2 = \mathrm{Im}\{ \mathrm{FFT}( \mathbf{x} \mathbf{a} ) \},
    \end{aligned}
\end{equation}</div>

<p>这里<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>为输入的矩阵，<span><span class="MathJax_Preview">\mathrm{FFT}(\cdot)</span><script type="math/tex">\mathrm{FFT}(\cdot)</script></span>是快速傅里叶变换。我们使用<span><span class="MathJax_Preview">\mathbf{y}_1</span><script type="math/tex">\mathbf{y}_1</script></span>和<span><span class="MathJax_Preview">\mathbf{y}_2</span><script type="math/tex">\mathbf{y}_2</script></span>来表示输出是具有两个通道的向量。我们考虑实现以下功能：</p>
<ul>
<li>该层输入一个形状为<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span></code>的向量组，输出一个形状为<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span></code>的矩阵组，其中<code>L</code>在<code>l</code>为奇数时，取<code>(L+1)/2</code>；在<code>L</code>为偶数时，取<code>L/2+1</code>；<code>2</code>是两个通道，分别表示傅里叶变换的实部值和虚部值，同时，从输出可以看出傅里叶变换将使信号长度折半；</li>
<li>参数只有<span><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>，它可以指定初始化器、正则化器和限制条件，就像<code>Dense</code>层一样；</li>
<li>我们不使用两输出的形式，而是使用单输出、两通道的形式来定义该层，是为了方便处理后续的步骤（计算损失函数）。</li>
</ul>
<p>这里我们介绍一种新的定义层的方法，即“使用层来定义层”。该层定义为<code class="codehilite"><span class="k">class</span> <span class="nc">FFTAffine</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span></code></p>
<div class="superfences-tabs">
<input name="__tabs_7" type="radio" id="__tab_7_0" checked="checked" />
<label for="__tab_7_0">FFTAffine.__init__</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;input_shape&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">and</span> <span class="s1">&#39;input_dim&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;input_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;input_dim&#39;</span><span class="p">),)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FFTAffine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_initializer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_regularizer</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">kernel_constraint</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">InputSpec</span><span class="p">(</span><span class="n">min_ndim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_7" type="radio" id="__tab_7_1" />
<label for="__tab_7_1">FFTAffine.build</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_Dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                        <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">,</span>
                        <span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">,</span>
                        <span class="n">kernel_constraint</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_Dense</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FFTAffine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_7" type="radio" id="__tab_7_2" />
<label for="__tab_7_2">FFTAffine.call</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_Dense</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="n">res_r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">res</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">res_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">res</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">res_r</span><span class="p">,</span> <span class="n">res_i</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_7" type="radio" id="__tab_7_3" />
<label for="__tab_7_3">FFTAffine.compute_output_shape</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_7" type="radio" id="__tab_7_4" />
<label for="__tab_7_4">FFTAffine.get_config</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;kernel_initializer&#39;</span><span class="p">:</span> <span class="n">initializers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">),</span>
        <span class="s1">&#39;kernel_regularizer&#39;</span><span class="p">:</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">),</span>
        <span class="s1">&#39;kernel_constraint&#39;</span><span class="p">:</span> <span class="n">constraints</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">base_config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">FFTAffine</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_config</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>
</td></tr></table></div>
</div>
<p>首先，我们需要观察的是<code>__init__</code>和<code>get_config</code>两个方法。由于该层只有一个参数<span><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>，我们因此只需要为它指定初始化器、正则化器和限制条件即可。这一步和之前处理第一层的情况相似。</p>
<p>接下来，观察<code>build</code>，与定义第一层情况不同的是，在这里我们不是使用基本API (例如<code>add_weights</code>)，而是来自<code>tf.keras.layers</code>的层API，<code>Dense</code>。我们将初始化时构建的三个实例馈入<code>Dense</code>的参数中。并且，在这一阶段，我们不调用<code>Dense</code>处理张量，而是直接获取<code>Dense</code>的实例。</p>
<details class="tip" open="open"><summary>提示</summary><p>注意我们在这里手动调用了<code>self.layer_Dense.build(input_shape)</code>。</p>
<p>在一些行内的人眼里，这一步是不可或缺的，因为只有调用了<code>build</code>方法，我们定义的<code>Dense</code>类才会实例化其内的参数。但事实不完全如此，即使我们去掉这一行，即不调用<code>Dense</code>的<code>build</code>方法，效果也完全一样。这是因为<code>Dense</code>的父类<code>Layer</code>（当然也是我们继承的父类）具有检查<code>self.built</code>是否为<code class="codehilite"><span class="bp">True</span></code>的能力，并在调用某些方法的时候，如果发现<code>self.built</code>为<code class="codehilite"><span class="bp">False</span></code>，则自动调用<code>build</code>。这属于<code>build</code>方法的隐式调用。</p>
<p>虽然如此，我们仍然提倡用户一定要手动定义<code>build</code>。其一是因为，这种显式的定义在逻辑上是通顺、符合人的直觉的；其二是因为，我们不能完全确保自定义层里的所有子层的<code>build</code>方法一定会在任何情况下都能隐式触发。况且，这种做法是完全可行的，活用<code>compute_output_shape</code>或<code>tf.shape</code>等方法，我们可以做到手动触发一个有多个子层的自定义层中的所有子层的<code>build</code>方法。</p>
</details>
<details class="tip" open="open"><summary>提示</summary><p>有些行内的人指出，在使用<code>build</code>方法时，应当显式地将子层的可训练、不可训练参数都反馈给自定义层的参数表（参见<a href="https://stackoverflow.com/questions/54194724/how-to-use-keras-layers-in-custom-keras-layer">StackOverflow的讨论串</a>），具体的操作如下：</p>
<div class="codehilite"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_Dense</span><span class="o">.</span><span class="n">trainable_weights</span>
<span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_variables</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_Dense</span><span class="o">.</span><span class="n">non_trainable_variables</span>
</pre></div>

<p>然而必须指出的是，这种做法是不正确的。因为观察<a href="https://github.com/tensorflow/tensorflow/blob/9dba78a2fa49f3118c2537f32e2741265dcf2f07/tensorflow/python/keras/engine/base_layer.py#L689">源代码</a>可以发现，<code>trainable_weights</code>和<code>non_trainable_variables</code>都是封装好的属性方法。私有变量<code>_trainable_weights</code>和<code>_non_trainable_variables</code>与前者不同的是，这两个私有变量包含的是<span></span><strong>直属于本层的可训练、不可训练变量</strong><span></span>；但前者的实现分别是<span></span><strong>本层和本层的所有子层的所有可训练、不可训练变量</strong><span></span>。因此，将子层的所有变量加诸自定义层的直属变量里，是多余、且容易造成误解的做法。</p>
</details>
<p>最后，观察<code>call</code>方法，在该方法里，我们首先将维度为<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span></code>的参数通过无bias的全连接层映射到<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span></code>，再压缩最后一维度，得到维度为<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">]</span></code>的向量，通过Tensorflow自带的实值FFT变换函数<code>tf.signal.rfft</code>，得到复数域的输出<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span></code>，对该输出分别取实部和虚部，再将两实值化的结果以通道的形式并在一起，最终我们就得到两通道的输出<code class="codehilite"><span class="p">[</span><span class="n">N</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span></code>。其中，第一个通道是傅里叶变换的实部，第二个通道是傅里叶变换的虚部。</p>
<details class="info" open="open"><summary>信息</summary><p>实际上，Tensorflow的官方教程给出了一种自定义层的范例，参看<a href="https://www.tensorflow.org/tutorials/eager/custom_layers">Custom layers</a>。在这一范例中，使用<code>tf.keras.Model</code>定义一个有多个子层的模型，且该模型的使用方法和<code>Layer</code>一样。从某种程度上，这种方法比我们使用的方法更简洁。然而，需要指出的是，<a href="https://keras-zh.readthedocs.io/models/about-keras-models/#model">Model类继承 - Keras中文文档</a>也提到了这种做法，但使用<code>Model</code>类继承会导致网络具体实现的细节变得不可追索，具体而言就是形如<code>Model.to_json</code>、<code>Model.to_yaml</code>、<code>Model.get_config</code>和<code>Model.save</code>等方法变得不可用。</p>
<p>我们的这种做法则不存在这个问题，因为我们在每个自定义层里都定义了<code>get_config</code>方法，从而使得我们可以像使用内置的层API一样来使用它们。</p>
</details>
<h4 id="_16">检测效果<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h4>
<p>注意，在两个自定义层都定义好后，需要在两层定义的最后，加上如下代码：</p>
<div class="codehilite"><pre><span></span><span class="n">customObjects</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;FFTAffine&#39;</span><span class="p">:</span> <span class="n">FFTAffine</span><span class="p">,</span>
    <span class="s1">&#39;UpDimAffine&#39;</span><span class="p">:</span> <span class="n">UpDimAffine</span>
<span class="p">}</span>
</pre></div>

<p>该字典提供了一个索引表，将字符串形式的层名称映射到具体实现的类Object上。我们在任何涉及读取层的设置，例如<code>from_json</code>、<code>load_model</code>等方法中，都需要传入该索引表，确保Keras知道如何从配置文件里恢复出我们自定义的层。</p>
<p>如下代码提供了一个简单的两个自定义层叠加在一起的测试</p>
<div class="superfences-tabs">
<input name="__tabs_8" type="radio" id="__tab_8_0" checked="checked" />
<label for="__tab_8_0">test_layers</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">test_layers</span><span class="p">():</span>
    <span class="c1"># Set model and see the summary of the model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">UpDimAffine</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,)),</span>
        <span class="n">FFTAffine</span><span class="p">(</span><span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
    <span class="c1"># perform the test</span>
    <span class="n">var_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">var_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">var_input</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">var_input</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">var_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">var_output</span><span class="p">)</span>

<span class="n">test_layers</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_8" type="radio" id="__tab_8_1" />
<label for="__tab_8_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span>_________________________________________________________________
Layer <span class="o">(</span><span class="nb">type</span><span class="o">)</span>                 Output Shape              Param <span class="c1">#</span>
<span class="o">=================================================================</span>
up_dim_affine <span class="o">(</span>UpDimAffine<span class="o">)</span>  <span class="o">(</span>None, <span class="m">5</span>, <span class="m">10</span><span class="o">)</span>             <span class="m">20</span>
_________________________________________________________________
fft_affine <span class="o">(</span>FFTAffine<span class="o">)</span>       <span class="o">(</span>None, <span class="m">3</span>, <span class="m">2</span><span class="o">)</span>              <span class="nv">10</span>
<span class="o">=================================================================</span>
Total params: <span class="m">30</span>
Trainable params: <span class="m">20</span>
Non-trainable params: <span class="m">10</span>
_________________________________________________________________
<span class="o">(</span><span class="m">2</span>, <span class="m">5</span><span class="o">)</span> <span class="o">(</span><span class="m">2</span>, <span class="m">3</span>, <span class="m">2</span><span class="o">)</span>
<span class="o">[[[</span>-3.25903225e+00  <span class="m">5</span>.96046448e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">1</span>.05201025e-07 -5.80141695e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">3</span>.23036957e-08 -3.17865378e-08<span class="o">]]</span>

 <span class="o">[[</span>-3.25903225e+00  <span class="m">5</span>.96046448e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">1</span>.05201025e-07 -5.80141695e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">3</span>.23036957e-08 -3.17865378e-08<span class="o">]]]</span>
</pre></div></div>
</div>
<details class="bug" open="open"><summary>Bug</summary><p>注意，Tensorflow目前的版本(r1.13)仍然有不完善之处。在上述测试中，如果我们把<code>tf.keras.losses.mean_squared_error</code>替换成<code>tf.keras.MeanSquaredError</code>，虽然该测试能正常跑通，但接下来读取已保存的网络时则会报错。这是由于目前版本的Tensorflow使用了部分废旧的API来定义读取配置的函数，在Github上的某个<a href="https://github.com/tensorflow/tensorflow/issues/25938">讨论串</a>，有人已经给出了解决方案，但仍然需要等候被新版Tensorflow采纳才能生效。</p>
</details>
<p>该测试首先通过顺序模型，引入了我们自定义的两个层，然后通过<code>summary</code>显示模型的详细结构，并通过<code>save</code>保存整个网络的模型配置以及具体的参数值。接下来使用一个值全为1的，形状为<code class="codehilite"><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span></code>的输入来测试该模型，并记录测试结果，与我们的预期完全相符。</p>
<p>同时，我们在设置两层的时候，刻意地令第二层的参数不可训练，实际显示的结果表明，该设置是成功的。第二个函数的10个参量确实在模型的记录里显示为不可训练的。</p>
<details class="info" open="open"><summary>信息</summary><p>关于如何保存网络，我们会在下一章详细展开。</p>
</details>
<p>接下来，为了证明我们的自定义层能完全正常地工作，我们进行读取测试，</p>
<div class="superfences-tabs">
<input name="__tabs_9" type="radio" id="__tab_9_0" checked="checked" />
<label for="__tab_9_0">test_read</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">test_read</span><span class="p">():</span>
    <span class="n">customObjects</span><span class="p">[</span><span class="s1">&#39;cos&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span>
    <span class="n">new_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">customObjects</span><span class="p">)</span>
    <span class="n">new_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
    <span class="n">var_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">var_output</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">var_input</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">var_input</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">var_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">var_output</span><span class="p">)</span>

<span class="n">test_read</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_9" type="radio" id="__tab_9_1" />
<label for="__tab_9_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span>_________________________________________________________________
Layer <span class="o">(</span><span class="nb">type</span><span class="o">)</span>                 Output Shape              Param <span class="c1">#</span>
<span class="o">=================================================================</span>
up_dim_affine <span class="o">(</span>UpDimAffine<span class="o">)</span>  <span class="o">(</span>None, <span class="m">5</span>, <span class="m">10</span><span class="o">)</span>             <span class="m">20</span>
_________________________________________________________________
fft_affine <span class="o">(</span>FFTAffine<span class="o">)</span>       <span class="o">(</span>None, <span class="m">3</span>, <span class="m">2</span><span class="o">)</span>              <span class="nv">10</span>
<span class="o">=================================================================</span>
Total params: <span class="m">30</span>
Trainable params: <span class="m">20</span>
Non-trainable params: <span class="m">10</span>
_________________________________________________________________
<span class="o">(</span><span class="m">2</span>, <span class="m">5</span><span class="o">)</span> <span class="o">(</span><span class="m">2</span>, <span class="m">3</span>, <span class="m">2</span><span class="o">)</span>
<span class="o">[[[</span>-3.25903225e+00  <span class="m">5</span>.96046448e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">1</span>.05201025e-07 -5.80141695e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">3</span>.23036957e-08 -3.17865378e-08<span class="o">]]</span>

 <span class="o">[[</span>-3.25903225e+00  <span class="m">5</span>.96046448e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">1</span>.05201025e-07 -5.80141695e-08<span class="o">]</span>
  <span class="o">[</span> <span class="m">3</span>.23036957e-08 -3.17865378e-08<span class="o">]]]</span>
</pre></div></div>
</div>
<p>在该测试里，我们的模型从配置到参数，都完完全全是从文件<code>my_model.h5</code>中读取的。注意我们馈入<code>customObjects</code>给<code>load_model</code>，使Keras能发现我们自己定义的层。同时，<code>customObjects</code>还需要添加<code>tf.math.cos</code>函数，这是因为该激活函数同样不在Keras内置的几种基本的激活函数之列。</p>
<p>我们用完全相同的输入来测试模型的输出，得到的结果和我们上一个测试完全一致，说明对该模型（包括我们自定义的两层）的保存是成功的。</p>
<p>观察两个测试的输出值，我们会发现，对三维的输出，在确定后两维下标<code>a, b</code>的情况下<code class="codehilite"><span class="p">[:,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span></code>的输出都是一样的。这是因为，第一维反映的是向量组中不同向量的测试结果，而我们馈入模型的向量组是两个值均为1的长度为5的向量。由于这两个向量完全相同，其对应的输出也完全相同。</p>
<h3 id="_17">数据生成<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h3>
<p>我们仍然使用自动生成的数据。我们重新继承了自<a href="../linear-classification">第一节：线性分类</a>里定义的数据集生成类，新定义的数据集生成器<code class="codehilite"><span class="k">class</span> <span class="nc">TestDataFFTSet</span><span class="p">(</span><span class="n">TestDataSet</span><span class="p">):</span></code></p>
<div class="superfences-tabs">
<input name="__tabs_10" type="radio" id="__tab_10_0" checked="checked" />
<label for="__tab_10_0">dparser.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">TestDataFFTSet</span><span class="p">(</span><span class="n">TestDataSet</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A generator of the data set for testing the non-linear regression model.</span>
<span class="sd">    y = cos(x w^T + 1 p^T) a</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale_x</span><span class="p">,</span> <span class="n">len_x</span><span class="p">,</span> <span class="n">omega</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Initialize the data generator.</span>
<span class="sd">        scale_x: the scale of input vector.</span>
<span class="sd">        len_x: the length of input vector.</span>
<span class="sd">        omega (w) [1 x N]: the inner linear transformation.</span>
<span class="sd">        phi (p) [1 x N]: the inner bias.</span>
<span class="sd">        a [N x 1]: the outer linear transormation.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s_x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">scale_x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">omega</span> <span class="o">=</span> <span class="n">omega</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phi</span> <span class="o">=</span> <span class="n">phi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len_x</span> <span class="o">=</span> <span class="n">len_x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mapfunc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">xu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">xu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">omega</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">y1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">xu</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">phi</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>
        <span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">y1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span>
        <span class="n">y_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">y2</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">y2</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_r</span><span class="p">,</span> <span class="n">y_i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">next_train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Get the next train batch: (x, y)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_test</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mapfunc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</td></tr></table></div>
</div>
<p>我们新定义的这个数据生成器，与以往的一个不同在于，其定义了<code>mapfunc</code>方法；而产生训练数据的原理，是用<code>mapfunc</code>将产生的测试数据（只有输入<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>）映射到输出<span><span class="MathJax_Preview">\mathbf{Y}</span><script type="math/tex">\mathbf{Y}</script></span>。这个数据集可以通过迭代不断产生随机数据，也可以通过<code>mapfunc</code>来将任意给定的向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>转换成<a href="#mjx-eqn-6"><span><span class="MathJax_Preview">(6)</span><script type="math/tex">(6)</script></span></a>定义的频域输出<span><span class="MathJax_Preview">\hat{\mathbf{Y}}</span><script type="math/tex">\hat{\mathbf{Y}}</script></span>。</p>
<p>特别地，这里计算矩阵的时候，不使用<code>np.matmul</code>而是<code>np.tensordot</code>，和我们为第一层定义的时候使用<code>tf.tensordot</code>的原因相同。该函数支持对两个高维度的张量，取其中的两个维度分别计算矩阵乘法。</p>
<p>接下来测试数据集的输出效果</p>
<div class="superfences-tabs">
<input name="__tabs_11" type="radio" id="__tab_11_0" checked="checked" />
<label for="__tab_11_0">dparser.py</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">test_dataset</span><span class="p">():</span>
    <span class="n">omega</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">dataSet</span> <span class="o">=</span> <span class="n">TestDataFFTSet</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">omega</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">dIter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dIter</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1j</span><span class="o">*</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">test_dataset</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_11" type="radio" id="__tab_11_1" />
<label for="__tab_11_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span><span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">14</span>.29735734  <span class="m">9</span>.75982541  <span class="m">4</span>.73928941  <span class="m">6</span>.83158726  <span class="m">5</span>.16604991  <span class="m">0</span>.66256222<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span> <span class="m">9</span>.32749042  <span class="m">5</span>.68157606  <span class="m">4</span>.86524786 <span class="m">11</span>.17296633  <span class="m">6</span>.37133611  <span class="m">7</span>.68757874<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">3</span>.97163879 <span class="m">9</span>.35646167 <span class="m">1</span>.43682653 <span class="m">4</span>.49838507 <span class="m">7</span>.39721013 <span class="m">4</span>.34096144<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">6</span>.56389599 <span class="m">5</span>.59993345 <span class="m">8</span>.19466732 <span class="m">0</span>.72835593 <span class="m">5</span>.01080391 <span class="m">9</span>.0552016 <span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">9</span>.71065508 <span class="m">3</span>.08608948 <span class="m">8</span>.72857359 <span class="m">9</span>.47081321 <span class="m">4</span>.87269945 <span class="m">7</span>.02108589<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">6</span>.05645098 <span class="m">6</span>.05961698 <span class="m">2</span>.98397442 <span class="m">8</span>.83888829 <span class="m">2</span>.91282992 <span class="m">5</span>.07843238<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">5</span>.11452286 <span class="m">1</span>.34310476 <span class="m">4</span>.15953687 <span class="m">3</span>.43588933 <span class="m">1</span>.7484992  <span class="m">0</span>.21387424<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">0</span>.63167972 <span class="m">8</span>.34622626 <span class="m">6</span>.21582338 <span class="m">5</span>.01146157 <span class="m">1</span>.50978382 <span class="m">1</span>.18373357<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">5</span>.88872479 <span class="m">6</span>.18109798 <span class="m">6</span>.97300166 <span class="m">4</span>.48064652 <span class="m">8</span>.13842369 <span class="m">6</span>.01989667<span class="o">]</span>
<span class="o">(</span><span class="m">100</span>, <span class="m">6</span>, <span class="m">2</span><span class="o">)</span> <span class="o">[</span><span class="m">1</span>.28678976 <span class="m">3</span>.08831315 <span class="m">5</span>.3226707  <span class="m">0</span>.86784854 <span class="m">7</span>.83722167 <span class="m">0</span>.98692777<span class="o">]</span>
</pre></div></div>
</div>
<p>我们产生的数据长度为10，参数的长度为12，我们在测试代码中，显示每次生成batch中，第一个样本的频谱强度。测试结果显示，频谱强度分布较为合理，且FFT后的数据长度为6=10/2+1，符合我们的预期。</p>
<h3 id="_18">定义类模型<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h3>
<p>与<a href="../linear-regression/#_13">上一节</a>相似，我们在本节使用的仍然是回归模型，因此，在主程序部分的代码改动不大。我们定义新的类<code class="codehilite"><span class="k">class</span> <span class="nc">NonLinRegHandle</span><span class="p">(</span><span class="n">ext</span><span class="o">.</span><span class="n">AdvNetworkBase</span><span class="p">):</span></code>，其中核心部分（构造方法）的代码如下：</p>
<div class="superfences-tabs">
<input name="__tabs_12" type="radio" id="__tab_12_0" checked="checked" />
<label for="__tab_12_0">class NonLinRegHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Construct a linear model and set the optimizer as Adam</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Construction</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">INPUT_SHAPE</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">upAff</span> <span class="o">=</span> <span class="n">ext</span><span class="o">.</span><span class="n">UpDimAffine</span><span class="p">(</span><span class="n">PARAMS_SHAPE</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                            <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomUniform</span><span class="p">(</span><span class="n">minval</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mf">3.0</span><span class="p">),</span>
                            <span class="n">bias_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomUniform</span><span class="p">(</span><span class="n">minval</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mf">2.0</span><span class="p">),</span>
                            <span class="n">kernel_constraint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">NonNeg</span><span class="p">(),</span>
                            <span class="n">bias_constraint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">NonNeg</span><span class="p">(),</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;up_dim_affine&#39;</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">dnAff</span> <span class="o">=</span> <span class="n">ext</span><span class="o">.</span><span class="n">FFTAffine</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fft_affine&#39;</span><span class="p">)(</span><span class="n">upAff</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">dnAff</span><span class="p">)</span>

    <span class="c1"># Set optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizerName</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">relation</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</td></tr></table></div>
</div>
<p>在这个模型中，除了输入层以外，其余的两层都分别是我们自定义的层。第一个层内有参数<span><span class="MathJax_Preview">\boldsymbol{\omega},~\boldsymbol{\phi}</span><script type="math/tex">\boldsymbol{\omega},~\boldsymbol{\phi}</script></span>，我们对这两个参数均加上了必须为正数的严格限制条件，同时对<span><span class="MathJax_Preview">\boldsymbol{\omega}</span><script type="math/tex">\boldsymbol{\omega}</script></span>，我们使用均匀分布<span><span class="MathJax_Preview">U(0.0,~3.0)</span><script type="math/tex">U(0.0,~3.0)</script></span>对其初始化，对<span><span class="MathJax_Preview">\boldsymbol{\phi}</span><script type="math/tex">\boldsymbol{\phi}</script></span>，我们使用均匀分布<span><span class="MathJax_Preview">U(0.0,~2.0)</span><script type="math/tex">U(0.0,~2.0)</script></span>对其初始化。在该层的最后，使用<span><span class="MathJax_Preview">\cos(\cdot)</span><script type="math/tex">\cos(\cdot)</script></span>函数作为激活函数。</p>
<p>第二层内有参数<span><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span>，我们直接使用默认的初始化器来对其初始化。</p>
<p>实际测试的过程中，我们发现上一节定义的<a href="../linear-regression/#mjx-eqn-15">相关系数</a>仍有缺陷。具体体现在，当两个被对比的向量中任何一个向量的某一维度的样本分布在方差为0时，分母<span><span class="MathJax_Preview">\sigma_1^{(i)} \sigma_2^{(i)} = 0</span><script type="math/tex">\sigma_1^{(i)} \sigma_2^{(i)} = 0</script></span> （其中<span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>表示向量的某一维度），从而导致该系数无法计算出结果。故而，我们考虑对其修正，在计算各维度相关系数的平均值时，排除掉那些无法计算相关系数的维度，改进后的代码如下：</p>
<div class="superfences-tabs">
<input name="__tabs_13" type="radio" id="__tab_13_0" checked="checked" />
<label for="__tab_13_0">class NonLinRegHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">relation</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">m_y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">m_y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">s_y_true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">m_y_true</span><span class="p">))</span>
    <span class="n">s_y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">m_y_pred</span><span class="p">))</span>
    <span class="n">s_denom</span> <span class="o">=</span> <span class="n">s_y_true</span> <span class="o">*</span> <span class="n">s_y_pred</span>
    <span class="n">s_numer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">m_y_true</span> <span class="o">*</span> <span class="n">m_y_pred</span>
    <span class="n">s_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">s_denom</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">s_numer</span><span class="p">,</span><span class="n">s_index</span><span class="p">)</span><span class="o">/</span><span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">s_denom</span><span class="p">,</span><span class="n">s_index</span><span class="p">))</span>
</pre></div>
</td></tr></table></div>
</div>
<h3 id="_19">调试<a class="headerlink" href="#_19" title="Permanent link">&para;</a></h3>
<p>在调试阶段，我们采用随机生成的参数作为真值。其中，<span><span class="MathJax_Preview">\boldsymbol{\omega} \in U(0.0,~3.0)</span><script type="math/tex">\boldsymbol{\omega} \in U(0.0,~3.0)</script></span>, <span><span class="MathJax_Preview">\boldsymbol{\phi} \in U(0.0,~2.0)</span><script type="math/tex">\boldsymbol{\phi} \in U(0.0,~2.0)</script></span>，<span><span class="MathJax_Preview">\mathbf{a} \in N(0.0,~1.0)</span><script type="math/tex">\mathbf{a} \in N(0.0,~1.0)</script></span>。然后，我们生成大量的<span><span class="MathJax_Preview">(\mathbf{x},~\mathbf{Y})</span><script type="math/tex">(\mathbf{x},~\mathbf{Y})</script></span>，其中<span><span class="MathJax_Preview">\mathbf{x} \in U(-3.0,~3.0)</span><script type="math/tex">\mathbf{x} \in U(-3.0,~3.0)</script></span>。注意在这个问题里，模型的输入输出向量是等长的，参数的长度不影响输出向量的长度。我们将参数的长度固定为10个元素，并定义如下函数</p>
<div class="superfences-tabs">
<input name="__tabs_14" type="radio" id="__tab_14_0" checked="checked" />
<label for="__tab_14_0">class NonLinRegHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">groupSort</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">):</span>
    <span class="n">sortind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">sortind</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:,</span> <span class="n">sortind</span><span class="p">]</span>
        <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>
</td></tr></table></div>
</div>
<p>该函数用于对一组相同长度的向量进行排序，这些向量不拘于行向量或列向量。排序的标准是第一个参数向量从小到大的顺序。定义该函数是为了修整我们的输出结果。在上文理论部分，我们已经说明，对于一组解，交换任意两个维度的值，不影响模型的效果。因此我们通过对预测值和真值分别进行排序，来评估两组解之间的差异程度。</p>
<div class="superfences-tabs">
<input name="__tabs_15" type="radio" id="__tab_15_0" checked="checked" />
<label for="__tab_15_0">class NonLinRegHandle</label>
<div class="superfences-content"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Initialization</span>
<span class="n">omega</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">PARAMS_SHAPE</span><span class="p">])</span>
<span class="n">phi</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">PARAMS_SHAPE</span><span class="p">])</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">PARAMS_SHAPE</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">dataSet</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">TestDataFFTSet</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">xLength</span><span class="p">,</span> <span class="n">omega</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="c1"># Generate a group of testing samples.</span>
<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">setSeed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="o">+</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">testBatchNum</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)</span>
<span class="c1"># Set the data set for training.</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">trainBatchNum</span><span class="p">)</span>
<span class="c1"># Construct the model and train it.</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">NonLinRegHandle</span><span class="p">(</span><span class="n">xLength</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">xLength</span><span class="p">,</span> <span class="n">learningRate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">learningRate</span><span class="p">,</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">steppe</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">steppe</span><span class="p">,</span> <span class="n">optimizerName</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">h</span><span class="o">.</span><span class="n">construct</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Begin to train:&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;---------------&#39;</span><span class="p">)</span>
<span class="n">record</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>

<span class="c1"># Generate a group of testing samples:</span>
<span class="n">dataSet</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">testBatchNum</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">xLength</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">xLength</span><span class="p">])</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">mapfunc</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">x2</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="p">,</span><span class="n">y2</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Check the testing results</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Begin to test:&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;---------------&#39;</span><span class="p">)</span>
<span class="n">yp</span><span class="p">,</span> <span class="n">loss_p</span><span class="p">,</span> <span class="n">corr_p</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Check the regressed values</span>
<span class="n">w</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;up_dim_affine&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;fft_affine&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Resort data</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">groupSort</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="c1"># The solution</span>
<span class="n">omega</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">groupSort</span><span class="p">(</span><span class="n">omega</span><span class="p">,</span> <span class="n">phi</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="c1"># The ground truth</span>

<span class="c1"># Save</span>
<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">outputData</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">np</span><span class="o">.</span><span class="n">savez_compressed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">outputData</span><span class="p">,</span> 
        <span class="n">epoch</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">corr</span> <span class="o">=</span> <span class="n">record</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;relation&#39;</span><span class="p">],</span> 
        <span class="n">test_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred_y</span> <span class="o">=</span> <span class="n">yp</span><span class="p">,</span> 
        <span class="n">pred_loss</span> <span class="o">=</span> <span class="n">loss_p</span><span class="p">,</span> <span class="n">pred_corr</span> <span class="o">=</span> <span class="n">corr_p</span><span class="p">,</span>
        <span class="n">W</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">omega</span><span class="o">=</span><span class="n">omega</span><span class="p">,</span> <span class="n">phi</span><span class="o">=</span><span class="n">phi</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span>
    <span class="p">)</span>
</pre></div>
</td></tr></table></div>
<input name="__tabs_15" type="radio" id="__tab_15_1" />
<label for="__tab_15_1">Output</label>
<div class="superfences-content"><div class="codehilite"><pre><span></span>_________________________________________________________________
Layer <span class="o">(</span><span class="nb">type</span><span class="o">)</span>                 Output Shape              Param <span class="c1">#</span>
<span class="o">=================================================================</span>
input_1 <span class="o">(</span>InputLayer<span class="o">)</span>         <span class="o">(</span>None, <span class="m">100</span><span class="o">)</span>               <span class="m">0</span>
_________________________________________________________________
up_dim_affine <span class="o">(</span>UpDimAffine<span class="o">)</span>  <span class="o">(</span>None, <span class="m">100</span>, <span class="m">10</span><span class="o">)</span>           <span class="m">20</span>
_________________________________________________________________
fft_affine <span class="o">(</span>FFTAffine<span class="o">)</span>       <span class="o">(</span>None, <span class="m">51</span>, <span class="m">2</span><span class="o">)</span>             <span class="nv">10</span>
<span class="o">=================================================================</span>
Total params: <span class="m">30</span>
Trainable params: <span class="m">30</span>
Non-trainable params: <span class="m">0</span>
_________________________________________________________________
Begin to train:
---------------
Epoch <span class="m">1</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 3s 5ms/step - loss: <span class="m">6</span>.8965 - relation: <span class="m">0</span>.9842
Epoch <span class="m">2</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">0</span>.0027 - relation: <span class="m">1</span>.0000
Epoch <span class="m">3</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">0</span>.0018 - relation: <span class="m">1</span>.0000
Epoch <span class="m">4</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">0</span>.0016 - relation: <span class="m">1</span>.0000
Epoch <span class="m">5</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">0</span>.0014 - relation: <span class="m">1</span>.0000
Epoch <span class="m">6</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">0</span>.0012 - relation: <span class="m">1</span>.0000
Epoch <span class="m">7</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">0</span>.0010 - relation: <span class="m">1</span>.0000
Epoch <span class="m">8</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">9</span>.0556e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">9</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">7</span>.9935e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">10</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">7</span>.0898e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">11</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">6</span>.3418e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">12</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">5</span>.6936e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">13</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">5</span>.1473e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">14</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">4</span>.6677e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">15</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">4</span>.2542e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">16</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">3</span>.8777e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">17</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">3</span>.5603e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">18</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">3</span>.2665e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">19</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">3</span>.0134e-04 - relation: <span class="m">1</span>.0000
Epoch <span class="m">20</span>/20
<span class="m">500</span>/500 <span class="o">[==============================]</span> - 2s 4ms/step - loss: <span class="m">2</span>.7940e-04 - relation: <span class="m">1</span>.0000
Begin to test:
---------------
<span class="m">11</span>/11 <span class="o">[==============================]</span> - 0s 6ms/sample - loss: <span class="m">2</span>.4728e-04 - relation: <span class="m">1</span>.0000
Evaluated loss <span class="o">(</span>losses.MeanSquaredError<span class="o">)</span> <span class="o">=</span> <span class="m">0</span>.0002472764754202217
Evaluated metric <span class="o">(</span>Pearson<span class="err">&#39;</span>s correlation<span class="o">)</span> <span class="o">=</span> <span class="m">0</span>.9999991
</pre></div></div>
</div>
<p>在测试阶段，我们除了生成10组随机数据以外，还生成了一组从<span><span class="MathJax_Preview">[-3, 3]</span><script type="math/tex">[-3, 3]</script></span>之间均匀增长的数据。这组数据与我们之前使用的随机数据分布不同，通过检测该数据的输出结果，我们可以验证我们拟合的这个参数模型是否具有一定的鲁棒性。</p>
<p>输入向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>的长度不但影响输出<span><span class="MathJax_Preview">\mathbf{Y}</span><script type="math/tex">\mathbf{Y}</script></span>的长度，也影响FFT的精度。因此，我们通过使用不同的向量长度分别进行测试，并对测试结果进行评估。调用测试的代码如下：</p>
<div class="codehilite"><pre><span></span>python lin-reg.py -sd <span class="m">1</span> -do test/<span class="o">{</span>length<span class="o">}</span> -xl <span class="o">{</span>length<span class="o">}</span>
</pre></div>

<p>通过指派不同的向量长度<code>{length}</code>，将输出保存到不同的文件里，以绘制它们的对比效果图。首先，我们观察训练过程的记录情况</p>
<table>
<thead>
<tr>
<th>损失函数 (MSE)</th>
<th>测度函数 (相关系数)</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="损失函数 (MSE)" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg-loss.svg" tag="1" title="损失函数 (MSE)" /></td>
<td><img alt="测度函数 (相关系数)" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg-corr.svg" tag="1" title="测度函数 (相关系数)" /></td>
</tr>
</tbody>
</table>
<p>可以看见，收敛的速度非常快。并且随着数据向量长度的增加，损失函数收敛到的值也增加。这是由于傅里叶变换的影响。我们使用的傅里叶变换是还没有标准化后的数据，因此，随着输入向量的增长，傅里叶变换的精度也提高，导致低频部分的数值明显变大，从而导致损失函数的收敛值增加。而相关系数显示，预测输出和真实值之间的线性相关性迅速趋近于1，印证该训练过程非常快。</p>
<details class="warning" open="open"><summary>注意</summary><p>需要重申的是，我们计算相关系数是基于不同样本的统计情况来确定的。因此为了估计出准确的的相关系数，我们的batch需要有足够多的样本。显然，1个样本的batch是无法用来计算相关系数的。这里我们的batch含有32个样本。</p>
</details>
<p>接下来运行测试集检查结果。我们对预测的频谱和真实频谱之间求均方根误差(RMSE)，结果如下：</p>
<table>
<thead>
<tr>
<th>均方根误差 (RMSE)</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="均方根误差 (RMSE)" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg-bar.svg" tag="2" title="均方根误差 (RMSE)" /></td>
</tr>
</tbody>
</table>
<p>由<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>知，我们的模型本质上其实是一个对向量个元素独立运算的函数，亦即元素级的函数。因此，<a href="#mjx-eqn-4"><span><span class="MathJax_Preview">(4)</span><script type="math/tex">(4)</script></span></a>可以被改写成</p>
<div class="overflow">\begin{align}
    y(x) = \sum_{i=1}^N a_i \cos ( \omega_i x + \varphi_i ).
\end{align}</div>

<p>如果我们输入一组向量，值在<span><span class="MathJax_Preview">[-3, 3]</span><script type="math/tex">[-3, 3]</script></span>之内从小到大均匀增长，那么对应的取傅里叶变换的输出向量，可以看成是响应<span><span class="MathJax_Preview">x \in (-3,~3)</span><script type="math/tex">x \in (-3,~3)</script></span>的频谱。我们在上述测试过程中，虽然使用了不同的向量长度<span><span class="MathJax_Preview">L</span><script type="math/tex">L</script></span>，但生成的最后一个测试向量<span><span class="MathJax_Preview">\mathbf{x}</span><script type="math/tex">\mathbf{x}</script></span>均是在<span><span class="MathJax_Preview">x \in (-3,~3)</span><script type="math/tex">x \in (-3,~3)</script></span>均匀采样得到的。因此，不同的向量长度的测试结果，对应的是同以频谱不同精度下的计算结果。我们将训练好的模型输出的频谱和真实数据生成的频谱对比，得到以下结果：</p>
<table>
<thead>
<tr>
<th>频谱响应</th>
<th>幅值</th>
<th>相位</th>
</tr>
</thead>
<tbody>
<tr>
<td>L=10</td>
<td><img alt="L=10的幅值" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/amp-0010.svg" tag="3" title="L=10的幅值" /></td>
<td><img alt="L=10的相位" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/ang-0010.svg" tag="4" title="L=10的相位" /></td>
</tr>
<tr>
<td>L=100</td>
<td><img alt="L=100的幅值" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/amp-0100.svg" tag="3" title="L=100的幅值" /></td>
<td><img alt="L=100的相位" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/ang-0100.svg" tag="4" title="L=100的相位" /></td>
</tr>
<tr>
<td>L=500</td>
<td><img alt="L=500的幅值" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/amp-0500.svg" tag="3" title="L=500的幅值" /></td>
<td><img alt="L=500的相位" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/ang-0500.svg" tag="4" title="L=500的相位" /></td>
</tr>
<tr>
<td>L=1000</td>
<td><img alt="L=1000的幅值" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/amp-1000.svg" tag="3" title="L=1000的幅值" /></td>
<td><img alt="L=1000的相位" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/ang-1000.svg" tag="4" title="L=1000的相位" /></td>
</tr>
</tbody>
</table>
<p>可见，我们的回归到的模型输出的频谱和真值的模型完全一致。</p>
<details class="question" open="open"><summary>问题</summary><p><em>如果一个模型在频域上对一个信号的回归是精确的，是否在原域上（即时域）的回归也是精确的？</em></p>
<p>正是如此。因为，考虑FFT的逆变换iFFT，作为一个线性变换，iFFT毫无疑问满足Lipschitz连续条件。这意味着，如果一个信号的在频域上的回归结果满足<span><span class="MathJax_Preview">\lVert \hat{\mathbf{Y}} - \mathbf{Y} \rVert &lt; \varepsilon</span><script type="math/tex">\lVert \hat{\mathbf{Y}} - \mathbf{Y} \rVert < \varepsilon</script></span>，则必有在时域上满足<span><span class="MathJax_Preview">\lVert \hat{\mathbf{y}} - \mathbf{y} \rVert &lt; C\varepsilon</span><script type="math/tex">\lVert \hat{\mathbf{y}} - \mathbf{y} \rVert < C\varepsilon</script></span>，其中<span><span class="MathJax_Preview">C</span><script type="math/tex">C</script></span>是一个有限的常量。</p>
<p>另一种思考方法是，iFFT和FFT互为逆变换，这说明这两者之间构成一一映射。如果两组信号的FFT相同，那么其对应的一一映射，iFFT，又或者说是原信号，是势必相同的。这意味着，如果一个模型能够在时域上回归到某组数据，那么其频域上也必然能回归到相同数据的频域表达，反之亦然。</p>
</details>
<p>最后，我们来观察三个参数向量的回归情况，比对不同测试回归到的参数向量和真值之间的差别，结果如下</p>
<table>
<thead>
<tr>
<th><span><span class="MathJax_Preview">\boldsymbol{\omega}</span><script type="math/tex">\boldsymbol{\omega}</script></span></th>
<th><span><span class="MathJax_Preview">\boldsymbol{\phi}</span><script type="math/tex">\boldsymbol{\phi}</script></span></th>
<th><span><span class="MathJax_Preview">\mathbf{a}</span><script type="math/tex">\mathbf{a}</script></span></th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="&lt;b&gt;ω&lt;/b&gt;" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/omega.svg" tag="5" title="<b>ω</b>" /></td>
<td><img alt="&lt;b&gt;φ&lt;/b&gt;" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/phi.svg" tag="5" title="<b>φ</b>" /></td>
<td><img alt="&lt;b&gt;a&lt;/b&gt;" class="img-fluid" src="../../../assets/images/book-1-x/nonlinreg/a.svg" tag="5" title="<b>a</b>" /></td>
</tr>
</tbody>
</table>
<p>鉴于模型的解具有高度的不确定性，我们发现我们回归到的结果受到初始化值的影响非常严重。尽管我们的回归模型确实拟合出了原函数的特性，但回归到的参数却和真值有明显的区别。</p>
<p>本节虽然使用了一个高度不确定的、却又简单的非线性函数作为例子，但我们所希望传达的，主要有以下两个要点：</p>
<ul>
<li>一个可以写成解析式的线性或非线性函数，可以轻易地被实现成Tensorflow-Keras模式下的可微模型。这种函数包括但不限于普通的<a href="https://www.tensorflow.org/api_docs/python/tf/math">数学函数</a>（例如指数函数、三角函数、贝塞尔函数等），<a href="https://www.tensorflow.org/api_docs/python/tf/signal/rfft">快速傅里叶变换</a>，<a href="https://www.tensorflow.org/api_docs/python/tf/signal/dct">离散余弦变换</a>，<a href="https://www.tensorflow.org/api_docs/python/tf/linalg">常规的线性代数操作</a>（例如行列式、特征值），<a href="https://www.tensorflow.org/api_docs/python/tf/linalg/svd">SVD分解</a>，等等。这些函数全部都已经被Tensorflow实现出来，可以通过内置API任意组合。更重要的是，在本节中，我们没有定义任何求取导数、梯度的方法，因为上述的每一个Tensorflow内置API，都已经内置了解析级别的梯度的计算方法。因此，对于一些简单的非线性模型，用户可以完全不用关心反向传播的过程，而是合心定意在编写正向传播上。从某种程度上，这大大降低了求解非线性问题的难度。</li>
<li>本节重点揭示的，是如何优雅地完成一个自定义层。截至笔者写到目前为止(03/17/2019)，未见网络上有登载类似的、规范的教程。如果用户能习惯按照本节的方式，扩展Tensorflow-Keras API，会带来两大好处：<ul>
<li>一些复杂的模块，例如Residual block，Inception block等，可以以封装好的形式利用起来，使得主程序的代码简洁干净；</li>
<li>使用和Keras源码一致的语言风格，确保我们编写的所有自定义API，都可以被Keras原生的存取工具（包括<code>to_json</code>,<code>save</code>等）正确地保存下来。</li>
</ul>
</li>
</ul>
<p>在后续的内容里，我们还会涉及自定义网络层的情况，但是我们就不会特别说明完整的定义流程。在本教程推进的过程中，我们会不断定义各种需要用到的网络层，从而不断丰富扩展模块<code>extension.py</code>的内容。到本教程结束的时候，我们期望能够建立一个对用户友好的、功能完善而又与Tensorflow-Keras源代码风格一致的扩展模块出来。这一模块将可以用来构建任何形式的Tensorflow工程。</p>
                
                  
                    <h2 id="__source">来源</h2>
                    
                    
                    
                    
                    <a href="https://github.com/cainmagi/tensorflow-guide/tree//1-3-nonlinear-regression" title="1-3-nonlinear-regression" class="md-source-file">
                      1-3-nonlinear-regression
                    </a>
                  
                
              
              
                


  <h2 id="__comments">评论</h2>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = "https://cainmagi.github.io/tensorflow-guide/book-1-x/chapter-1/nonlinear-regression/";
      this.page.identifier =
        "book-1-x/chapter-1/nonlinear-regression/";
    };
    (function() {
      var d = document, s = d.createElement("script");
      s.src = "//tensorflow-guide.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>

              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../linear-regression/" title="线性回归" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                线性回归
              </span>
            </div>
          </a>
        
        
          <a href="../../../release-notes/" title="更新记录" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                更新记录
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Yuchen Jin
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../../assets/fonts/font-awesome.css">
    
      <a href="https://cainmagi.github.io/" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="mailto:cainmagi@gmail.com" class="md-footer-social__link fa fa-envelope"></a>
    
      <a href="https://github.com/cainmagi" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/squidfunk" class="md-footer-social__link fa fa-steam"></a>
    
      <a href="https://weibo.com/u/5885093621" class="md-footer-social__link fa fa-weibo"></a>
    
      <a href="https://www.youtube.com/channel/UCzqpNK5qFMy5_cI1i0Z1nQw" class="md-footer-social__link fa fa-youtube-play"></a>
    
      <a href="https://music.163.com/#/user/home?id=276304206" class="md-footer-social__link fa fa-music"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.43ad2ac2.js"></script>
      
        
        
          
          <script src="../../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../../assets/javascripts/lunr/lunr.jp.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js"></script>
      
        <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
      
        <script src="../../../javascripts/simpleLightbox.min.js"></script>
      
        <script src="../../../javascripts/extensions.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>